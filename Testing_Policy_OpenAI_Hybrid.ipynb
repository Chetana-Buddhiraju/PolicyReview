{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MNgdbS9YtYt"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community langchain-openai faiss-cpu openai pandas openpyxl pypdf tqdm tenacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtytR8DNYtZN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZE3yPftkYtZZ"
      },
      "outputs": [],
      "source": [
        "# Guided retrieval configuration\n",
        "clause_to_sections = {\n",
        "    \"4.1\": \"ACC.01.00 ME1\",\n",
        "    \"4.3\": \"ACC.04.05 ME1\",\n",
        "    \"4.4\": \"ACC.01.00 ME3\",\n",
        "    \"4.5\": \"ACC.01.00 ME2\",\n",
        "    \"4.6\": \"ACC.03.00 ME1\",\n",
        "    \"4.7\": \"ACC.03.00 ME3\",\n",
        "    \"4.8\": \"ACC.03.01 ME3\",\n",
        "    \"5.1.1\": \"ACC.03.01 ME2 and ME3\",\n",
        "    \"5.1.2\": \"ACC.03.00 ME1\",\n",
        "    \"5.1.3\": \"ACC.01.00 ME5, ACC.03.00 ME2, ME3 and ME4\",\n",
        "    \"5.1.4\": \"ACC.03.00 ME6, ACC.02.02 ME2\",\n",
        "    \"5.1.5\": \"ACC.03.00 ME6\",\n",
        "    \"5.1.8\": \"ACC.03.00 ME5, ACC.03.01 ME1, ME2 and ME3\",\n",
        "    \"5.3.1\": \"ACC.01.00 ME6\",\n",
        "    \"5.3.2\": \"ACC.03.01 ME1, ME2 and ME3\",\n",
        "    \"5.3.3\": \"ACC.03.01 ME3\",\n",
        "    \"5.3.4\": \"ACC.03.01 ME3\",\n",
        "    \"5.4.1\": \"ACC.03.01 ME3\",\n",
        "    \"5.5.1\": \"ACC.03.01 ME1 and ME3\",\n",
        "    \"5.5.2\": \"ACC.03.00 ME6\",\n",
        "    \"5.6\": \"ACC.03.01 ME3\",\n",
        "    \"5.6.1\": \"Ministry of Health Circular No. MH 53:08/4 vol 6 – Guidelines for Inter-Hospital Transfer\",\n",
        "    \"5.6.2\": \"ACC.03.00 ME6\",\n",
        "    \"5.6.3\": \"ACC.03.00 ME5\",\n",
        "    \"5.6.4\": \"ACC.03.01 ME1, ME2 and ME3\",\n",
        "    \"5.7\": \"ACC.03.01 ME and ME3\",\n",
        "}\n",
        "\n",
        "synonyms = {\n",
        "    \"transfer\": [\"handover\", \"relocation\", \"patient movement\"],\n",
        "    \"policy\": [\"guideline\", \"procedure\"],\n",
        "    \"emergency\": [\"urgent\", \"critical\", \"immediate\"],\n",
        "}\n",
        "\n",
        "def expand_query_with_synonyms(query: str) -> str:\n",
        "    words = query.split()\n",
        "    expanded = []\n",
        "    for w in words:\n",
        "        expanded.append(w)\n",
        "        if w.lower() in synonyms:\n",
        "            expanded.extend(synonyms[w.lower()])\n",
        "    return \" \".join(expanded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flzHE7aWYtZo",
        "outputId": "4cc0c078-4b6d-48bd-81e9-171176586c7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OPENAI_API_KEY (input hidden): ··········\n",
            "API Key starts with: sk-pr\n"
          ]
        }
      ],
      "source": [
        "# API key\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    try:\n",
        "        from getpass import getpass\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY (input hidden): \")\n",
        "    except Exception:\n",
        "        raise ValueError(\"OPENAI_API_KEY is required.\")\n",
        "\n",
        "print(\"API Key starts with:\", os.getenv(\"OPENAI_API_KEY\")[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C88mYC9MYtZt"
      },
      "outputs": [],
      "source": [
        "def setup_logging() -> logging.Logger:\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "    )\n",
        "    return logging.getLogger(\"policy_pipeline\")\n",
        "\n",
        "logger = setup_logging()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9pEzms_YtZw"
      },
      "outputs": [],
      "source": [
        "class PolicyDocumentChunker:\n",
        "    def __init__(self):\n",
        "        self.clause_patterns = [\n",
        "            r'(\\d+\\.\\d+(?:\\.\\d+)?)\\.\\s*(.*?)(?=\\n\\d+\\.\\d+(?:\\.\\d+)?\\.|\\n[A-Z]+\\s*:|\\n\\n[A-Z]|\\Z)',\n",
        "            r'(\\d+\\.\\d+(?:\\.\\d+)?)\\s+((?:[A-Z][^.]*\\..*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z))',\n",
        "            r'(\\d+\\.\\d+\\.\\d+)\\.\\s*(.*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z)',\n",
        "        ]\n",
        "        self.definition_pattern = r'(\\d+\\.\\d+)\\.\\s+([A-Z]+(?:\\s+[A-Z]+)*)\\s+refers\\s+to\\s+(.*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z)'\n",
        "        self.section_header_pattern = r'(\\d+)\\.\\s+([A-Z][A-Z\\s]{3,})\\s*\\n'\n",
        "\n",
        "    def extract_comprehensive_chunks(self, text: str) -> List[Dict]:\n",
        "        text = self._preprocess_text(text)\n",
        "        clauses = self._extract_clauses(text)\n",
        "        definitions = self._extract_definitions(text)\n",
        "        sections = self._extract_sections(text)\n",
        "        all_chunks = clauses + definitions + sections\n",
        "        enhanced_chunks = self._add_contextual_info(all_chunks, text)\n",
        "        return enhanced_chunks\n",
        "\n",
        "    def _preprocess_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', text)\n",
        "        text = re.sub(r'(\\d+\\.\\d+(?:\\.\\d+)?)\\s*\\.\\s*', r'\\1. ', text)\n",
        "        text = re.sub(r'Page\\s+\\d+\\s+of\\s+\\d+', '', text)\n",
        "        text = re.sub(r'Document\\s+No:\\s+[A-Z0-9\\-]+', '', text)\n",
        "        return text\n",
        "\n",
        "    def _extract_clauses(self, text: str) -> List[Dict]:\n",
        "        clauses = []\n",
        "        for pattern in self.clause_patterns:\n",
        "            matches = re.finditer(pattern, text, re.DOTALL | re.MULTILINE)\n",
        "            for match in matches:\n",
        "                clause_num = match.group(1)\n",
        "                content = match.group(2).strip()\n",
        "                content = re.sub(r'\\s+', ' ', content)\n",
        "                content = re.sub(r'\\n+', '\\n', content)\n",
        "                if len(content) > 20 and not self._is_duplicate_clause(clauses, clause_num):\n",
        "                    clauses.append({\n",
        "                        'clause_number': clause_num,\n",
        "                        'content': content,\n",
        "                        'content_type': 'clause',\n",
        "                        'word_count': len(content.split()),\n",
        "                        'char_count': len(content),\n",
        "                    })\n",
        "        return clauses\n",
        "\n",
        "    def _extract_definitions(self, text: str) -> List[Dict]:\n",
        "        definitions = []\n",
        "        matches = re.finditer(self.definition_pattern, text, re.DOTALL | re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            clause_num = match.group(1)\n",
        "            term = match.group(2).strip()\n",
        "            definition = re.sub(r'\\s+', ' ', match.group(3).strip())\n",
        "            definitions.append({\n",
        "                'clause_number': clause_num,\n",
        "                'term': term,\n",
        "                'definition': definition,\n",
        "                'content': f\"{term} refers to {definition}\",\n",
        "                'content_type': 'definition',\n",
        "                'word_count': len(definition.split()),\n",
        "                'char_count': len(definition),\n",
        "            })\n",
        "        return definitions\n",
        "\n",
        "    def _extract_sections(self, text: str) -> List[Dict]:\n",
        "        sections = []\n",
        "        matches = re.finditer(self.section_header_pattern, text, re.MULTILINE)\n",
        "        for match in matches:\n",
        "            section_num = match.group(1)\n",
        "            section_title = match.group(2).strip()\n",
        "            start_pos = match.end()\n",
        "            next_section = re.search(r'\\n\\d+\\.\\s+[A-Z][A-Z\\s]{3,}', text[start_pos:])\n",
        "            if next_section:\n",
        "                section_content = text[start_pos:start_pos + next_section.start()]\n",
        "            else:\n",
        "                section_content = text[start_pos:start_pos + 1000]\n",
        "            section_content = section_content.strip()\n",
        "            if len(section_content) > 50:\n",
        "                sections.append({\n",
        "                    'clause_number': f\"{section_num}.0\",\n",
        "                    'section_title': section_title,\n",
        "                    'content': f\"Section {section_num}: {section_title}\\n\\n{section_content}\",\n",
        "                    'content_type': 'section',\n",
        "                    'word_count': len(section_content.split()),\n",
        "                    'char_count': len(section_content),\n",
        "                })\n",
        "        return sections\n",
        "\n",
        "    def _add_contextual_info(self, chunks: List[Dict], full_text: str) -> List[Dict]:\n",
        "        enhanced_chunks = []\n",
        "        for chunk in chunks:\n",
        "            enhanced_content = self._build_contextual_content(chunk, chunks)\n",
        "            enhanced_chunk = chunk.copy()\n",
        "            enhanced_chunk['enhanced_content'] = enhanced_content\n",
        "            enhanced_chunks.append(enhanced_chunk)\n",
        "        return enhanced_chunks\n",
        "\n",
        "    def _build_contextual_content(self, chunk: Dict, all_chunks: List[Dict]) -> str:\n",
        "        content_parts = [chunk['content']]\n",
        "        if chunk['content_type'] == 'clause':\n",
        "            related_defs = self._find_related_definitions(chunk, all_chunks)\n",
        "            if related_defs:\n",
        "                content_parts.append(\"Relevant definitions:\")\n",
        "                for def_chunk in related_defs[:2]:\n",
        "                    content_parts.append(f\"- {def_chunk['content']}\")\n",
        "        section_context = self._find_section_context(chunk, all_chunks)\n",
        "        if section_context:\n",
        "            content_parts.insert(0, f\"Context: {section_context}\")\n",
        "        return \"\\n\".join(content_parts)\n",
        "\n",
        "    def _find_related_definitions(self, chunk: Dict, all_chunks: List[Dict]) -> List[Dict]:\n",
        "        definitions = [c for c in all_chunks if c['content_type'] == 'definition']\n",
        "        related = []\n",
        "        chunk_content_lower = chunk['content'].lower()\n",
        "        for def_chunk in definitions:\n",
        "            term_lower = def_chunk['term'].lower()\n",
        "            if term_lower in chunk_content_lower:\n",
        "                related.append(def_chunk)\n",
        "        return related\n",
        "\n",
        "    def _find_section_context(self, chunk: Dict, all_chunks: List[Dict]) -> Optional[str]:\n",
        "        sections = [c for c in all_chunks if c['content_type'] == 'section']\n",
        "        clause_num = chunk['clause_number']\n",
        "        if '.' in clause_num:\n",
        "            section_num = clause_num.split('.')[0]\n",
        "            for section in sections:\n",
        "                if section['clause_number'].startswith(f\"{section_num}.\"):\n",
        "                    return section.get('section_title', '')\n",
        "        return None\n",
        "\n",
        "    def _is_duplicate_clause(self, existing_clauses: List[Dict], clause_num: str) -> bool:\n",
        "        return any(c['clause_number'] == clause_num for c in existing_clauses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV40pzctYtZ7"
      },
      "outputs": [],
      "source": [
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    chunker = PolicyDocumentChunker()\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def analyze_chunking_results(chunks: List[Dict]) -> Dict:\n",
        "    analysis = {\n",
        "        'total_chunks': len(chunks),\n",
        "        'clause_numbers': [c['clause_number'] for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown'],\n",
        "        'unknown_clauses': len([c for c in chunks if c.get('clause_number') == 'unknown']),\n",
        "        'chunk_types': {}\n",
        "    }\n",
        "    for chunk in chunks:\n",
        "        chunk_type = chunk.get('content_type', 'unknown')\n",
        "        analysis['chunk_types'][chunk_type] = analysis['chunk_types'].get(chunk_type, 0) + 1\n",
        "    if chunks:\n",
        "        analysis['extraction_success_rate'] = ((len(chunks) - analysis['unknown_clauses']) / len(chunks)) * 100\n",
        "    return analysis\n",
        "\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8II2PC4AYtaD"
      },
      "outputs": [],
      "source": [
        "class ComplianceStatus(Enum):\n",
        "    COMPLIANT = \"Compliant\"\n",
        "    PARTIALLY_COMPLIANT = \"Partially Compliant\"\n",
        "    NON_COMPLIANT = \"Non-Compliant\"\n",
        "    INSUFFICIENT_INFO = \"Insufficient Information\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ComplianceAnalysis:\n",
        "    clause_number: str\n",
        "    compliance_status: ComplianceStatus\n",
        "    confidence_score: float\n",
        "    key_gaps: List[str]\n",
        "    required_changes: List[str]\n",
        "    jci_references: List[str]\n",
        "    risk_level: str\n",
        "    full_analysis: str\n",
        "\n",
        "\n",
        "class ClauseComparisonAnalyzer:\n",
        "    def __init__(self, api_key: str, model: str = \"gpt-4o\"):\n",
        "        self.client = OpenAI(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.config = {\n",
        "            'max_tokens': 1000,\n",
        "            'temperature': 0.1,\n",
        "            'top_p': 0.9,\n",
        "        }\n",
        "\n",
        "    def compare_clause_to_jci(self, clause_number: str, clause_text: str, jci_references: List[Dict]) -> ComplianceAnalysis:\n",
        "        prompt = self._build_comparison_prompt(clause_number, clause_text, jci_references)\n",
        "        response = self._call_gpt4o(prompt)\n",
        "        analysis = self._parse_response(response, clause_number)\n",
        "        return analysis\n",
        "\n",
        "    def _build_comparison_prompt(self, clause_number: str, clause_text: str, jci_references: List[Dict]) -> str:\n",
        "        jci_text = self._format_jci_references(jci_references)\n",
        "        return f\"\"\"You are a healthcare compliance expert specializing in JCI hospital accreditation standards.\n",
        "\n",
        "**TASK:** Compare the policy clause against JCI standards and identify specific changes needed.\n",
        "\n",
        "**POLICY CLAUSE {clause_number}:**\n",
        "{clause_text}\n",
        "\n",
        "**RELEVANT JCI STANDARDS:**\n",
        "{jci_text}\n",
        "\n",
        "**ANALYSIS FRAMEWORK:**\n",
        "\n",
        "1. **REQUIREMENT COMPARISON:** Compare each requirement in the policy clause against the JCI standards above.\n",
        "\n",
        "2. **GAP IDENTIFICATION:** Identify specific gaps between policy and JCI requirements.\n",
        "\n",
        "3. **CHANGE SPECIFICATION:** For each gap, specify the exact change needed to achieve compliance.\n",
        "\n",
        "**PROVIDE STRUCTURED OUTPUT:**\n",
        "\n",
        "**COMPLIANCE STATUS:** [Compliant/Partially Compliant/Non-Compliant]\n",
        "\n",
        "**CONFIDENCE LEVEL:** [0-100%]\n",
        "\n",
        "**SPECIFIC GAPS IDENTIFIED:**\n",
        "• [Gap 1]: [Specific difference between policy and JCI standard]\n",
        "• [Gap 2]: [Specific difference between policy and JCI standard]\n",
        "\n",
        "**REQUIRED CHANGES:**\n",
        "• [Change 1]: [Exact modification needed] → [JCI Standard this addresses]\n",
        "• [Change 2]: [Exact modification needed] → [JCI Standard this addresses]\n",
        "\n",
        "**RISK LEVEL:** [High/Medium/Low]\n",
        "\n",
        "**JCI STANDARDS REFERENCED:**\n",
        "• [Standard]: [Specific requirement]\n",
        "\n",
        "Focus on actionable, specific changes rather than general recommendations.\"\"\"\n",
        "\n",
        "    def _format_jci_references(self, references: List[Dict]) -> str:\n",
        "        if not references:\n",
        "            return \"No specific JCI references available for comparison.\"\n",
        "        formatted = []\n",
        "        for i, ref in enumerate(references, 1):\n",
        "            text = ref.get('text', '')\n",
        "            if len(text) > 300:\n",
        "                text = text[:300] + \"...\"\n",
        "            formatted.append(f\"**JCI Reference {i}:**\\n{text}\")\n",
        "        return \"\\n\\n\".join(formatted)\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def _call_gpt4o(self, prompt: str) -> str:\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a senior healthcare compliance consultant. Provide specific, actionable analysis focused on exact changes needed for JCI compliance.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            **self.config\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def _parse_response(self, response: str, clause_number: str) -> ComplianceAnalysis:\n",
        "        import re as _re\n",
        "        compliance_match = _re.search(r'\\*\\*COMPLIANCE STATUS:\\*\\*\\s*([^\\n]+)', response, _re.IGNORECASE)\n",
        "        compliance_status = ComplianceStatus.INSUFFICIENT_INFO\n",
        "        if compliance_match:\n",
        "            status_text = compliance_match.group(1).strip().lower()\n",
        "            if \"non-compliant\" in status_text:\n",
        "                compliance_status = ComplianceStatus.NON_COMPLIANT\n",
        "            elif \"partially compliant\" in status_text:\n",
        "                compliance_status = ComplianceStatus.PARTIALLY_COMPLIANT\n",
        "            elif \"compliant\" in status_text:\n",
        "                compliance_status = ComplianceStatus.COMPLIANT\n",
        "\n",
        "        confidence_match = _re.search(r'\\*\\*CONFIDENCE LEVEL:\\*\\*\\s*(\\d+)%', response)\n",
        "        confidence_score = float(confidence_match.group(1)) / 100 if confidence_match else 0.0\n",
        "\n",
        "        gaps_section = _re.search(r'\\*\\*SPECIFIC GAPS IDENTIFIED:\\*\\*(.*?)(?=\\*\\*[A-Z ]+:\\*\\*|\\Z)', response, _re.DOTALL)\n",
        "        key_gaps = []\n",
        "        if gaps_section:\n",
        "            gaps_text = gaps_section.group(1)\n",
        "            key_gaps = [g.strip() for g in _re.findall(r'•\\s*([^\\n•]+)', gaps_text) if g.strip()]\n",
        "\n",
        "        changes_section = _re.search(r'\\*\\*REQUIRED CHANGES:\\*\\*(.*?)(?=\\*\\*[A-Z ]+:\\*\\*|\\Z)', response, _re.DOTALL)\n",
        "        required_changes = []\n",
        "        if changes_section:\n",
        "            changes_text = changes_section.group(1)\n",
        "            required_changes = [c.strip() for c in _re.findall(r'•\\s*([^\\n•]+)', changes_text) if c.strip()]\n",
        "\n",
        "        jci_section = _re.search(r'\\*\\*JCI STANDARDS REFERENCED:\\*\\*(.*?)(?=\\*\\*[A-Z ]+:\\*\\*|\\Z)', response, _re.DOTALL)\n",
        "        jci_references = []\n",
        "        if jci_section:\n",
        "            jci_text = jci_section.group(1)\n",
        "            jci_references = [r.strip() for r in _re.findall(r'•\\s*([^\\n•]+)', jci_text) if r.strip()]\n",
        "\n",
        "        risk_match = _re.search(r'\\*\\*RISK LEVEL:\\*\\*\\s*([^\\n]+)', response, _re.IGNORECASE)\n",
        "        risk_level = risk_match.group(1).strip() if risk_match else \"Unknown\"\n",
        "\n",
        "        return ComplianceAnalysis(\n",
        "            clause_number=clause_number,\n",
        "            compliance_status=compliance_status,\n",
        "            confidence_score=confidence_score,\n",
        "            key_gaps=key_gaps,\n",
        "            required_changes=required_changes,\n",
        "            jci_references=jci_references,\n",
        "            risk_level=risk_level,\n",
        "            full_analysis=response\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-haP1GAmYtaM"
      },
      "outputs": [],
      "source": [
        "# Load policy PDF, chunk, and save chunking results\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\"   # <- change as needed\n",
        "JCI_PDF = \"/content/ESS Standards_7th Ed .pdf\"  # <- change as needed\n",
        "\n",
        "validate_pdf_path(POLICY_PDF)\n",
        "logger.info(\"Loading and chunking policy document...\")\n",
        "policy_chunks = load_and_chunk_pdf(POLICY_PDF)\n",
        "policy_analysis = analyze_chunking_results(policy_chunks)\n",
        "logger.info(f\"Chunking complete: {policy_analysis}\")\n",
        "\n",
        "pd.DataFrame(policy_chunks).to_excel(\"enhanced_chunking_results.xlsx\", index=False)\n",
        "logger.info(\"Saved enhanced_chunking_results.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCBRAhhQYtaU"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=EMBEDDING_MODEL,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8Cr6oi5YtaX"
      },
      "outputs": [],
      "source": [
        "# Load and chunk JCI, split into smaller pieces, build FAISS\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ4BwzacYtaZ"
      },
      "outputs": [],
      "source": [
        "# Hybrid retrieval (guided-first, automated fallback)\n",
        "\n",
        "def retrieve_jci_hybrid(clause_number: str, clause_text: str, k: int = 5) -> List[Dict]:\n",
        "    expanded_text = expand_query_with_synonyms(clause_text)\n",
        "    mapped = clause_to_sections.get(clause_number)\n",
        "\n",
        "    # fetch expanded candidates\n",
        "    docs = jci_db.similarity_search(expanded_text, k=max(3*k, 15))\n",
        "    if mapped:\n",
        "        filtered = [d for d in docs if mapped.lower() in d.page_content.lower()]\n",
        "        if filtered:\n",
        "            return [{\"text\": d.page_content, \"metadata\": d.metadata} for d in filtered[:k]]\n",
        "\n",
        "    # fallback to vanilla similarity on original clause text\n",
        "    auto_docs = jci_db.similarity_search(clause_text, k=k)\n",
        "    return [{\"text\": d.page_content, \"metadata\": d.metadata} for d in auto_docs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIv8kVvIYtab"
      },
      "outputs": [],
      "source": [
        "# Analysis config and batch run\n",
        "MODEL = \"gpt-4o\"\n",
        "RATE_LIMIT_DELAY = 2.0\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "analyzer = ClauseComparisonAnalyzer(api_key=os.getenv(\"OPENAI_API_KEY\"), model=MODEL)\n",
        "\n",
        "def batch_analyze_clauses_with_progress(chunks: List[Dict]) -> List[ComplianceAnalysis]:\n",
        "    results: List[ComplianceAnalysis] = []\n",
        "    work_items = [c for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown']\n",
        "\n",
        "    with tqdm(total=len(work_items), desc=\"Analyzing clauses\") as pbar:\n",
        "        for chunk in work_items:\n",
        "            clause_number = chunk['clause_number']\n",
        "            clause_text = chunk.get('enhanced_content', chunk.get('content', ''))\n",
        "            jci_refs = retrieve_jci_hybrid(clause_number, clause_text)\n",
        "            try:\n",
        "                analysis = analyzer.compare_clause_to_jci(clause_number, clause_text, jci_refs)\n",
        "                results.append(analysis)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Analysis failed for clause {clause_number}: {e}\")\n",
        "                results.append(\n",
        "                    ComplianceAnalysis(\n",
        "                        clause_number=clause_number,\n",
        "                        compliance_status=ComplianceStatus.INSUFFICIENT_INFO,\n",
        "                        confidence_score=0.0,\n",
        "                        key_gaps=[f\"Analysis failed: {str(e)}\"],\n",
        "                        required_changes=[\"Retry analysis\"],\n",
        "                        jci_references=[],\n",
        "                        risk_level=\"Unknown\",\n",
        "                        full_analysis=f\"Error: {str(e)}\"\n",
        "                    )\n",
        "                )\n",
        "            time.sleep(RATE_LIMIT_DELAY)\n",
        "            pbar.update(1)\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-GcWVJXYtae",
        "outputId": "55794850-23c6-4015-85a5-efbcc25e6e65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyzing clauses: 100%|██████████| 10/10 [01:28<00:00,  8.82s/it]\n",
            "Analyzing clauses: 100%|██████████| 10/10 [01:35<00:00,  9.51s/it]\n",
            "Analyzing clauses: 100%|██████████| 6/6 [00:56<00:00,  9.50s/it]\n"
          ]
        }
      ],
      "source": [
        "# Run batches and save\n",
        "all_results: List[ComplianceAnalysis] = []\n",
        "\n",
        "for i in range(0, len(policy_chunks), BATCH_SIZE):\n",
        "    batch = policy_chunks[i:i+BATCH_SIZE]\n",
        "    logger.info(f\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\")\n",
        "    batch_results = batch_analyze_clauses_with_progress(batch)\n",
        "    all_results.extend(batch_results)\n",
        "\n",
        "logger.info(f\"Total analyzed: {len(all_results)}\")\n",
        "\n",
        "# Save to Excel\n",
        "def save_comparison_results(analyses: List[ComplianceAnalysis], output_file: str):\n",
        "    data = []\n",
        "    for analysis in analyses:\n",
        "        data.append({\n",
        "            'clause_number': analysis.clause_number,\n",
        "            'compliance_status': analysis.compliance_status.value,\n",
        "            'confidence_score': f\"{analysis.confidence_score:.0%}\",\n",
        "            'risk_level': analysis.risk_level,\n",
        "            'gaps_identified': ' | '.join(analysis.key_gaps),\n",
        "            'required_changes': ' | '.join(analysis.required_changes),\n",
        "            'jci_standards_cited': ' | '.join(analysis.jci_references),\n",
        "            'detailed_analysis': analysis.full_analysis\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        'total_analyzed': len(analyses),\n",
        "        'compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.COMPLIANT]),\n",
        "        'partially_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.PARTIALLY_COMPLIANT]),\n",
        "        'non_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.NON_COMPLIANT]),\n",
        "        'high_risk': len([a for a in analyses if 'high' in a.risk_level.lower()]),\n",
        "    }\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(data).to_excel(writer, sheet_name='Clause Analysis', index=False)\n",
        "        pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "save_comparison_results(all_results, \"policy_vs_jci_hybrid.xlsx\")\n",
        "logger.info(\"Results saved to policy_vs_jci_hybrid.xlsx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "oJQj_OekYtag",
        "outputId": "43790447-8471-4bed-f100-6fc5ef130cea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chunking results: {'total_chunks': 26, 'clause_numbers': ['5.1', '5.2', '1.1', '1.2', '2.1', '3.1', '3.2', '3.3', '3.4', '3.5', '3.6', '3.7', '3.8', '4.1', '4.3', '4.5', '4.6', '4.8', '6.1', '6.3', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0'], 'unknown_clauses': 0, 'chunk_types': {'clause': 20, 'section': 6}, 'extraction_success_rate': 100.0}\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "Out of range float values are not JSON compliant: nan",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0060d40a-77a6-4bf9-9b57-32a7fe205a0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clause_number</th>\n",
              "      <th>content</th>\n",
              "      <th>content_type</th>\n",
              "      <th>word_count</th>\n",
              "      <th>char_count</th>\n",
              "      <th>enhanced_content</th>\n",
              "      <th>chunk_id</th>\n",
              "      <th>source_file</th>\n",
              "      <th>section_title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>1 Request should be made by a member of the re...</td>\n",
              "      <td>clause</td>\n",
              "      <td>59</td>\n",
              "      <td>466</td>\n",
              "      <td>Context: GUIDELINES\\n1 Request should be made ...</td>\n",
              "      <td>old Transfer 290523 .pdf::chunk_1</td>\n",
              "      <td>/content/old Transfer 290523 .pdf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.2</td>\n",
              "      <td>1 The decision to transfer patients to another...</td>\n",
              "      <td>clause</td>\n",
              "      <td>67</td>\n",
              "      <td>535</td>\n",
              "      <td>Context: GUIDELINES\\n1 The decision to transfe...</td>\n",
              "      <td>old Transfer 290523 .pdf::chunk_2</td>\n",
              "      <td>/content/old Transfer 290523 .pdf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.1</td>\n",
              "      <td>To provide guidelines for healthcare team to c...</td>\n",
              "      <td>clause</td>\n",
              "      <td>16</td>\n",
              "      <td>116</td>\n",
              "      <td>Context: PURPOSE\\nTo provide guidelines for he...</td>\n",
              "      <td>old Transfer 290523 .pdf::chunk_3</td>\n",
              "      <td>/content/old Transfer 290523 .pdf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.2</td>\n",
              "      <td>To ensure that patient’s information is convey...</td>\n",
              "      <td>clause</td>\n",
              "      <td>19</td>\n",
              "      <td>124</td>\n",
              "      <td>Context: PURPOSE\\nTo ensure that patient’s inf...</td>\n",
              "      <td>old Transfer 290523 .pdf::chunk_4</td>\n",
              "      <td>/content/old Transfer 290523 .pdf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.1</td>\n",
              "      <td>Patienttransfersduringthecourseofahospitaladmi...</td>\n",
              "      <td>clause</td>\n",
              "      <td>44</td>\n",
              "      <td>323</td>\n",
              "      <td>Context: POLICY\\nPatienttransfersduringthecour...</td>\n",
              "      <td>old Transfer 290523 .pdf::chunk_5</td>\n",
              "      <td>/content/old Transfer 290523 .pdf</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0060d40a-77a6-4bf9-9b57-32a7fe205a0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0060d40a-77a6-4bf9-9b57-32a7fe205a0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0060d40a-77a6-4bf9-9b57-32a7fe205a0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f57a11d2-6f27-4db1-a0d0-778d8c377dd4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f57a11d2-6f27-4db1-a0d0-778d8c377dd4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f57a11d2-6f27-4db1-a0d0-778d8c377dd4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  clause_number                                            content  \\\n",
              "0           5.1  1 Request should be made by a member of the re...   \n",
              "1           5.2  1 The decision to transfer patients to another...   \n",
              "2           1.1  To provide guidelines for healthcare team to c...   \n",
              "3           1.2  To ensure that patient’s information is convey...   \n",
              "4           2.1  Patienttransfersduringthecourseofahospitaladmi...   \n",
              "\n",
              "  content_type  word_count  char_count  \\\n",
              "0       clause          59         466   \n",
              "1       clause          67         535   \n",
              "2       clause          16         116   \n",
              "3       clause          19         124   \n",
              "4       clause          44         323   \n",
              "\n",
              "                                    enhanced_content  \\\n",
              "0  Context: GUIDELINES\\n1 Request should be made ...   \n",
              "1  Context: GUIDELINES\\n1 The decision to transfe...   \n",
              "2  Context: PURPOSE\\nTo provide guidelines for he...   \n",
              "3  Context: PURPOSE\\nTo ensure that patient’s inf...   \n",
              "4  Context: POLICY\\nPatienttransfersduringthecour...   \n",
              "\n",
              "                            chunk_id                        source_file  \\\n",
              "0  old Transfer 290523 .pdf::chunk_1  /content/old Transfer 290523 .pdf   \n",
              "1  old Transfer 290523 .pdf::chunk_2  /content/old Transfer 290523 .pdf   \n",
              "2  old Transfer 290523 .pdf::chunk_3  /content/old Transfer 290523 .pdf   \n",
              "3  old Transfer 290523 .pdf::chunk_4  /content/old Transfer 290523 .pdf   \n",
              "4  old Transfer 290523 .pdf::chunk_5  /content/old Transfer 290523 .pdf   \n",
              "\n",
              "  section_title  \n",
              "0           NaN  \n",
              "1           NaN  \n",
              "2           NaN  \n",
              "3           NaN  \n",
              "4           NaN  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Chunking results:\", policy_analysis)\n",
        "display(pd.DataFrame(policy_chunks).head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edb6f93d"
      },
      "source": [
        "# Task\n",
        "Integrate BM25 retrieval into the existing retrieval pipeline for the JCI dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbceaf50"
      },
      "source": [
        "## Install bm25 library\n",
        "\n",
        "### Subtask:\n",
        "Add a new cell to install the `rank_bm25` library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23b44721"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to install the `rank_bm25` library. This requires adding a new code cell with the pip installation command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4ffd8912"
      },
      "outputs": [],
      "source": [
        "!pip install -q rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c91bfdeb"
      },
      "source": [
        "## Update imports\n",
        "\n",
        "### Subtask:\n",
        "Add the necessary import for `BM25Okapi` to the existing imports cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8faa90fe"
      },
      "source": [
        "**Reasoning**:\n",
        "Add the import statement for `BM25Okapi` to the existing import cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "a4d38ae3",
        "outputId": "5f2af409-1217-4879-8982-1139148406be"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1981896298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_text_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPyPDFLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorstores\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from rank_bm25 import BM25Okapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb6b3849"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `langchain_community` was not found. This likely means the kernel session was reset or the environment changed. Re-run the initial installation cell to ensure all necessary libraries, including `langchain_community`, are installed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61430ae3"
      },
      "source": [
        "# Task\n",
        "Integrate BM25 retrieval into the existing Python notebook for hybrid search, modifying the code cells to include installation, imports, index building, and result combination with the existing FAISS retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09d69c87"
      },
      "source": [
        "## Install bm25 library\n",
        "\n",
        "### Subtask:\n",
        "Modify the first code cell to include the `rank_bm25` installation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b165dace"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to modify the first code cell to include the `rank_bm25` installation. I will edit the code cell with cell_id `-MNgdbS9YtYt` and add `rank_bm25` to the list of libraries to be installed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ef19b7a",
        "outputId": "be924229-0f06-4b9f-bdbc-68727907cd55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/2.5 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-community langchain-openai faiss-cpu openai pandas openpyxl pypdf tqdm tenacity rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "712c4cd2"
      },
      "source": [
        "## Update imports\n",
        "\n",
        "### Subtask:\n",
        "Update imports\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e8039f2"
      },
      "source": [
        "**Reasoning**:\n",
        "Re-running the initial installation cell is necessary because the previous import cell failed due to a missing module, indicating a potential environment issue or kernel restart.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c165f03a"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community langchain-openai faiss-cpu openai pandas openpyxl pypdf tqdm tenacity rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2864c585"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the required libraries are installed, the import cell needs to be re-run to include the `BM25Okapi` import and ensure all necessary modules are available for subsequent steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4732f126"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Optional\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from rank_bm25 import BM25Okapi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b037f05d"
      },
      "source": [
        "## Build bm25 index\n",
        "\n",
        "### Subtask:\n",
        "Create a new function to build a BM25 index from the JCI chunk texts and integrate it into the existing JCI processing logic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1a55538"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `build_bm25_index` function and integrate it into the JCI processing code cell to build the BM25 index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "23cc8088",
        "outputId": "f776c257-6ab6-437d-9de3-8e3586b69705"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'validate_pdf_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1115429631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvalidate_pdf_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJCI_PDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading and chunking JCI standards...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mjci_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_chunk_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJCI_PDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'validate_pdf_path' is not defined"
          ]
        }
      ],
      "source": [
        "def build_bm25_index(texts: List[str]) -> BM25Okapi:\n",
        "    \"\"\"Builds a BM25 index from a list of text documents.\"\"\"\n",
        "    tokenized_corpus = [doc.split() for doc in texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    return bm25\n",
        "\n",
        "# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n",
        "\n",
        "# Build BM25 index\n",
        "jci_bm25 = build_bm25_index(split_jci_texts)\n",
        "logger.info(f\"BM25 index built with {len(split_jci_texts)} JCI pieces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bc67e28"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because functions like `validate_pdf_path`, `load_and_chunk_pdf`, and `build_faiss_in_batches` were not defined in the current execution context, even though they were defined in previous cells. The entire code block from the previous attempt needs to be re-run, including the definitions of these functions, to fix the `NameError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "az4mQAV6kI-I",
        "outputId": "254a2a86-eeb1-424e-fa2d-a5761f51c50c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'JCI_PDF' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1351660501.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mvalidate_pdf_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJCI_PDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading and chunking JCI standards...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mjci_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_chunk_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJCI_PDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'JCI_PDF' is not defined"
          ]
        }
      ],
      "source": [
        "def build_bm25_index(texts: List[str]) -> BM25Okapi:\n",
        "    \"\"\"Builds a BM25 index from a list of text documents.\"\"\"\n",
        "    tokenized_corpus = [doc.split() for doc in texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    return bm25\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    chunker = PolicyDocumentChunker()\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n",
        "\n",
        "# Build BM25 index\n",
        "jci_bm25 = build_bm25_index(split_jci_texts)\n",
        "logger.info(f\"BM25 index built with {len(split_jci_texts)} JCI pieces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22c2883a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `JCI_PDF` variable was not defined in the current execution context. This variable is defined in a previous cell. The entire code block from the previous attempt needs to be re-run, including the definition of `JCI_PDF` and other necessary variables like `embeddings` and `PolicyDocumentChunker`, to fix the `NameError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "XXU9Oyl4kMEl",
        "outputId": "8d91636b-0a86-4da7-e271-d83cf1af3d7f"
      },
      "outputs": [
        {
          "ename": "OpenAIError",
          "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3222990299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Embeddings (re-instantiated for context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mEMBEDDING_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text-embedding-3-small\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m embeddings = OpenAIEmbeddings(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMBEDDING_MODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0msync_specific\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"http_client\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_client\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mclient_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msync_specific\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenai_proxy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhttp_async_client\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             raise OpenAIError(\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;34m\"The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             )\n",
            "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
          ]
        }
      ],
      "source": [
        "# Policy and JCI PDF paths (re-defined for context)\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\"   # <- change as needed\n",
        "JCI_PDF = \"/content/ESS Standards_7th Ed .pdf\"  # <- change as needed\n",
        "\n",
        "# Embeddings (re-instantiated for context)\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=EMBEDDING_MODEL,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# Chunker (re-instantiated for context)\n",
        "chunker = PolicyDocumentChunker()\n",
        "\n",
        "def build_bm25_index(texts: List[str]) -> BM25Okapi:\n",
        "    \"\"\"Builds a BM25 index from a list of text documents.\"\"\"\n",
        "    tokenized_corpus = [doc.split() for doc in texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    return bm25\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    # Use the chunker from the outer scope\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n",
        "\n",
        "# Build BM25 index\n",
        "jci_bm25 = build_bm25_index(split_jci_texts)\n",
        "logger.info(f\"BM25 index built with {len(split_jci_texts)} JCI pieces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "170c05b7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `OPENAI_API_KEY` environment variable was not set or accessible when the `OpenAIEmbeddings` object was instantiated. This likely indicates that the environment variable set in an earlier cell was lost. Re-running the cell that sets the API key environment variable should fix this issue. Then, re-run the code block that defines variables and functions and builds the indices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW3lFw1vkOkf",
        "outputId": "7b679761-ee55-42d9-8ee6-0924bb0f36aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OPENAI_API_KEY (input hidden): ··········\n",
            "API Key starts with: sk-pr\n"
          ]
        }
      ],
      "source": [
        "# API key\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    try:\n",
        "        from getpass import getpass\n",
        "        os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OPENAI_API_KEY (input hidden): \")\n",
        "    except Exception:\n",
        "        raise ValueError(\"OPENAI_API_KEY is required.\")\n",
        "\n",
        "print(\"API Key starts with:\", os.getenv(\"OPENAI_API_KEY\")[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cb7b3a1"
      },
      "source": [
        "**Reasoning**:\n",
        "The API key is now set. Re-run the code block that defines the necessary functions and variables, loads and chunks the JCI PDF, splits the chunks into smaller text pieces, and builds both FAISS and BM25 indices to continue with the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6b743dde",
        "outputId": "ba713070-c42d-413b-b2fb-5e64d2c36045"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'PolicyDocumentChunker' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1446843849.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Chunker (re-instantiated for context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicyDocumentChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_bm25_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBM25Okapi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PolicyDocumentChunker' is not defined"
          ]
        }
      ],
      "source": [
        "# Policy and JCI PDF paths (re-defined for context)\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\"   # <- change as needed\n",
        "JCI_PDF = \"/content/ESS Standards_7th Ed .pdf\"  # <- change as needed\n",
        "\n",
        "# Embeddings (re-instantiated for context)\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=EMBEDDING_MODEL,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# Chunker (re-instantiated for context)\n",
        "chunker = PolicyDocumentChunker()\n",
        "\n",
        "def build_bm25_index(texts: List[str]) -> BM25Okapi:\n",
        "    \"\"\"Builds a BM25 index from a list of text documents.\"\"\"\n",
        "    tokenized_corpus = [doc.split() for doc in texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    return bm25\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    # Use the chunker from the outer scope\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n",
        "\n",
        "\n",
        "# Build BM25 index\n",
        "jci_bm25 = build_bm25_index(split_jci_texts)\n",
        "logger.info(f\"BM25 index built with {len(split_jci_texts)} JCI pieces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f40de770"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `PolicyDocumentChunker` was not defined. This class is defined in an earlier cell. To fix this, the definition of `PolicyDocumentChunker` needs to be included in the current code block along with the other necessary definitions and the logic for building the indices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5kyYOBuXkmwH",
        "outputId": "89cf7c7e-137a-4cf8-d49d-bb7b29ee945a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'logger' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-69292668.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0mvalidate_pdf_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJCI_PDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading and chunking JCI standards...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0mjci_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_chunk_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJCI_PDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'logger' is not defined"
          ]
        }
      ],
      "source": [
        "# Policy and JCI PDF paths (re-defined for context)\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\"   # <- change as needed\n",
        "JCI_PDF = \"/content/ESS Standards_7th Ed .pdf\"  # <- change as needed\n",
        "\n",
        "# Embeddings (re-instantiated for context)\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=EMBEDDING_MODEL,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# PolicyDocumentChunker definition (re-included for context)\n",
        "class PolicyDocumentChunker:\n",
        "    def __init__(self):\n",
        "        self.clause_patterns = [\n",
        "            r'(\\d+\\.\\d+(?:\\.\\d+)?)\\.\\s*(.*?)(?=\\n\\d+\\.\\d+(?:\\.\\d+)?\\.|\\n[A-Z]+\\s*:|\\n\\n[A-Z]|\\Z)',\n",
        "            r'(\\d+\\.\\d+(?:\\.\\d+)?)\\s+((?:[A-Z][^.]*\\..*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z))',\n",
        "            r'(\\d+\\.\\d+\\.\\d+)\\.\\s*(.*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z)',\n",
        "        ]\n",
        "        self.definition_pattern = r'(\\d+\\.\\d+)\\.\\s+([A-Z]+(?:\\s+[A-Z]+)*)\\s+refers\\s+to\\s+(.*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z)'\n",
        "        self.section_header_pattern = r'(\\d+)\\.\\s+([A-Z][A-Z\\s]{3,})\\s*\\n'\n",
        "\n",
        "    def extract_comprehensive_chunks(self, text: str) -> List[Dict]:\n",
        "        text = self._preprocess_text(text)\n",
        "        clauses = self._extract_clauses(text)\n",
        "        definitions = self._extract_definitions(text)\n",
        "        sections = self._extract_sections(text)\n",
        "        all_chunks = clauses + definitions + sections\n",
        "        enhanced_chunks = self._add_contextual_info(all_chunks, text)\n",
        "        return enhanced_chunks\n",
        "\n",
        "    def _preprocess_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', text)\n",
        "        text = re.sub(r'(\\d+\\.\\d+(?:\\.\\d+)?)\\s*\\.\\s*', r'\\1. ', text)\n",
        "        text = re.sub(r'Page\\s+\\d+\\s+of\\s+\\d+', '', text)\n",
        "        text = re.sub(r'Document\\s+No:\\s+[A-Z0-9\\-]+', '', text)\n",
        "        return text\n",
        "\n",
        "    def _extract_clauses(self, text: str) -> List[Dict]:\n",
        "        clauses = []\n",
        "        for pattern in self.clause_patterns:\n",
        "            matches = re.finditer(pattern, text, re.DOTALL | re.MULTILINE)\n",
        "            for match in matches:\n",
        "                clause_num = match.group(1)\n",
        "                content = match.group(2).strip()\n",
        "                content = re.sub(r'\\s+', ' ', content)\n",
        "                content = re.sub(r'\\n+', '\\n', content)\n",
        "                if len(content) > 20 and not self._is_duplicate_clause(clauses, clause_num):\n",
        "                    clauses.append({\n",
        "                        'clause_number': clause_num,\n",
        "                        'content': content,\n",
        "                        'content_type': 'clause',\n",
        "                        'word_count': len(content.split()),\n",
        "                        'char_count': len(content),\n",
        "                    })\n",
        "        return clauses\n",
        "\n",
        "    def _extract_definitions(self, text: str) -> List[Dict]:\n",
        "        definitions = []\n",
        "        matches = re.finditer(self.definition_pattern, text, re.DOTALL | re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            clause_num = match.group(1)\n",
        "            term = match.group(2).strip()\n",
        "            definition = re.sub(r'\\s+', ' ', match.group(3).strip())\n",
        "            definitions.append({\n",
        "                'clause_number': clause_num,\n",
        "                'term': term,\n",
        "                'definition': definition,\n",
        "                'content': f\"{term} refers to {definition}\",\n",
        "                'content_type': 'definition',\n",
        "                'word_count': len(definition.split()),\n",
        "                'char_count': len(definition),\n",
        "            })\n",
        "        return definitions\n",
        "\n",
        "    def _extract_sections(self, text: str) -> List[Dict]:\n",
        "        sections = []\n",
        "        matches = re.finditer(self.section_header_pattern, text, re.MULTILINE)\n",
        "        for match in matches:\n",
        "            section_num = match.group(1)\n",
        "            section_title = match.group(2).strip()\n",
        "            start_pos = match.end()\n",
        "            next_section = re.search(r'\\n\\d+\\.\\s+[A-Z][A-Z\\s]{3,}', text[start_pos:])\n",
        "            if next_section:\n",
        "                section_content = text[start_pos:start_pos + next_section.start()]\n",
        "            else:\n",
        "                section_content = text[start_pos:start_pos + 1000]\n",
        "            section_content = section_content.strip()\n",
        "            if len(section_content) > 50:\n",
        "                sections.append({\n",
        "                    'clause_number': f\"{section_num}.0\",\n",
        "                    'section_title': section_title,\n",
        "                    'content': f\"Section {section_num}: {section_title}\\n\\n{section_content}\",\n",
        "                    'content_type': 'section',\n",
        "                    'word_count': len(section_content.split()),\n",
        "                    'char_count': len(section_content),\n",
        "                })\n",
        "        return sections\n",
        "\n",
        "    def _add_contextual_info(self, chunks: List[Dict], full_text: str) -> List[Dict]:\n",
        "        enhanced_chunks = []\n",
        "        for chunk in chunks:\n",
        "            enhanced_content = self._build_contextual_content(chunk, chunks)\n",
        "            enhanced_chunk = chunk.copy()\n",
        "            enhanced_chunk['enhanced_content'] = enhanced_content\n",
        "            enhanced_chunks.append(enhanced_chunk)\n",
        "        return enhanced_chunks\n",
        "\n",
        "    def _build_contextual_content(self, chunk: Dict, all_chunks: List[Dict]) -> str:\n",
        "        content_parts = [chunk['content']]\n",
        "        if chunk['content_type'] == 'clause':\n",
        "            related_defs = self._find_related_definitions(chunk, all_chunks)\n",
        "            if related_defs:\n",
        "                content_parts.append(\"Relevant definitions:\")\n",
        "                for def_chunk in related_defs[:2]:\n",
        "                    content_parts.append(f\"- {def_chunk['content']}\")\n",
        "        section_context = self._find_section_context(chunk, all_chunks)\n",
        "        if section_context:\n",
        "            content_parts.insert(0, f\"Context: {section_context}\")\n",
        "        return \"\\n\".join(content_parts)\n",
        "\n",
        "    def _find_related_definitions(self, chunk: Dict, all_chunks: List[Dict]) -> List[Dict]:\n",
        "        definitions = [c for c in all_chunks if c['content_type'] == 'definition']\n",
        "        related = []\n",
        "        chunk_content_lower = chunk['content'].lower()\n",
        "        for def_chunk in definitions:\n",
        "            term_lower = def_chunk['term'].lower()\n",
        "            if term_lower in chunk_content_lower:\n",
        "                related.append(def_chunk)\n",
        "        return related\n",
        "\n",
        "    def _find_section_context(self, chunk: Dict, all_chunks: List[Dict]) -> Optional[str]:\n",
        "        sections = [c for c in all_chunks if c['content_type'] == 'section']\n",
        "        clause_num = chunk['clause_number']\n",
        "        if '.' in clause_num:\n",
        "            section_num = clause_num.split('.')[0]\n",
        "            for section in sections:\n",
        "                if section['clause_number'].startswith(f\"{section_num}.\"):\n",
        "                    return section.get('section_title', '')\n",
        "        return None\n",
        "\n",
        "    def _is_duplicate_clause(self, existing_clauses: List[Dict], clause_num: str) -> bool:\n",
        "        return any(c['clause_number'] == clause_num for c in existing_clauses)\n",
        "\n",
        "# Chunker (re-instantiated after definition)\n",
        "chunker = PolicyDocumentChunker()\n",
        "\n",
        "def build_bm25_index(texts: List[str]) -> BM25Okapi:\n",
        "    \"\"\"Builds a BM25 index from a list of text documents.\"\"\"\n",
        "    tokenized_corpus = [doc.split() for doc in texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    return bm25\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    # Use the chunker from the outer scope\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n",
        "\n",
        "# Build BM25 index\n",
        "jci_bm25 = build_bm25_index(split_jci_texts)\n",
        "logger.info(f\"BM25 index built with {len(split_jci_texts)} JCI pieces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d1d154f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `logger` object was not defined. This object is initialized in an earlier cell using the `setup_logging` function. To fix this, the `setup_logging` function definition and the initialization of the `logger` object need to be included in the current code block along with the other necessary definitions and the logic for building the indices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LIqmTkUDkrlW"
      },
      "outputs": [],
      "source": [
        "# Setup logging (re-included for context)\n",
        "def setup_logging() -> logging.Logger:\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
        "    )\n",
        "    return logging.getLogger(\"policy_pipeline\")\n",
        "\n",
        "logger = setup_logging()\n",
        "\n",
        "# Policy and JCI PDF paths (re-defined for context)\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\"   # <- change as needed\n",
        "JCI_PDF = \"/content/ESS Standards_7th Ed .pdf\"  # <- change as needed\n",
        "\n",
        "# Embeddings (re-instantiated for context)\n",
        "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=EMBEDDING_MODEL,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "# PolicyDocumentChunker definition (re-included for context)\n",
        "class PolicyDocumentChunker:\n",
        "    def __init__(self):\n",
        "        self.clause_patterns = [\n",
        "            r'(\\d+\\.\\d+(?:\\.\\d+)?)\\.\\s*(.*?)(?=\\n\\d+\\.\\d+(?:\\.\\d+)?\\.|\\n[A-Z]+\\s*:|\\n\\n[A-Z]|\\Z)',\n",
        "            r'(\\d+\\.\\d+(?:\\.\\d+)?)\\s+((?:[A-Z][^.]*\\..*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z))',\n",
        "            r'(\\d+\\.\\d+\\.\\d+)\\.\\s*(.*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z)',\n",
        "        ]\n",
        "        self.definition_pattern = r'(\\d+\\.\\d+)\\.\\s+([A-Z]+(?:\\s+[A-Z]+)*)\\s+refers\\s+to\\s+(.*?)(?=\\n\\d+\\.\\d+|\\n[A-Z]+\\s*:|\\Z)'\n",
        "        self.section_header_pattern = r'(\\d+)\\.\\s+([A-Z][A-Z\\s]{3,})\\s*\\n'\n",
        "\n",
        "    def extract_comprehensive_chunks(self, text: str) -> List[Dict]:\n",
        "        text = self._preprocess_text(text)\n",
        "        clauses = self._extract_clauses(text)\n",
        "        definitions = self._extract_definitions(text)\n",
        "        sections = self._extract_sections(text)\n",
        "        all_chunks = clauses + definitions + sections\n",
        "        enhanced_chunks = self._add_contextual_info(all_chunks, text)\n",
        "        return enhanced_chunks\n",
        "\n",
        "    def _preprocess_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', text)\n",
        "        text = re.sub(r'(\\d+\\.\\d+(?:\\.\\d+)?)\\s*\\.\\s*', r'\\1. ', text)\n",
        "        text = re.sub(r'Page\\s+\\d+\\s+of\\s+\\d+', '', text)\n",
        "        text = re.sub(r'Document\\s+No:\\s+[A-Z0-9\\-]+', '', text)\n",
        "        return text\n",
        "\n",
        "    def _extract_clauses(self, text: str) -> List[Dict]:\n",
        "        clauses = []\n",
        "        for pattern in self.clause_patterns:\n",
        "            matches = re.finditer(pattern, text, re.DOTALL | re.MULTILINE)\n",
        "            for match in matches:\n",
        "                clause_num = match.group(1)\n",
        "                content = match.group(2).strip()\n",
        "                content = re.sub(r'\\s+', ' ', content)\n",
        "                content = re.sub(r'\\n+', '\\n', content)\n",
        "                if len(content) > 20 and not self._is_duplicate_clause(clauses, clause_num):\n",
        "                    clauses.append({\n",
        "                        'clause_number': clause_num,\n",
        "                        'content': content,\n",
        "                        'content_type': 'clause',\n",
        "                        'word_count': len(content.split()),\n",
        "                        'char_count': len(content),\n",
        "                    })\n",
        "        return clauses\n",
        "\n",
        "    def _extract_definitions(self, text: str) -> List[Dict]:\n",
        "        definitions = []\n",
        "        matches = re.finditer(self.definition_pattern, text, re.DOTALL | re.IGNORECASE)\n",
        "        for match in matches:\n",
        "            clause_num = match.group(1)\n",
        "            term = match.group(2).strip()\n",
        "            definition = re.sub(r'\\s+', ' ', match.group(3).strip())\n",
        "            definitions.append({\n",
        "                'clause_number': clause_num,\n",
        "                'term': term,\n",
        "                'definition': definition,\n",
        "                'content': f\"{term} refers to {definition}\",\n",
        "                'content_type': 'definition',\n",
        "                'word_count': len(definition.split()),\n",
        "                'char_count': len(definition),\n",
        "            })\n",
        "        return definitions\n",
        "\n",
        "    def _extract_sections(self, text: str) -> List[Dict]:\n",
        "        sections = []\n",
        "        matches = re.finditer(self.section_header_pattern, text, re.MULTILINE)\n",
        "        for match in matches:\n",
        "            section_num = match.group(1)\n",
        "            section_title = match.group(2).strip()\n",
        "            start_pos = match.end()\n",
        "            next_section = re.search(r'\\n\\d+\\.\\s+[A-Z][A-Z\\s]{3,}', text[start_pos:])\n",
        "            if next_section:\n",
        "                section_content = text[start_pos:start_pos + next_section.start()]\n",
        "            else:\n",
        "                section_content = text[start_pos:start_pos + 1000]\n",
        "            section_content = section_content.strip()\n",
        "            if len(section_content) > 50:\n",
        "                sections.append({\n",
        "                    'clause_number': f\"{section_num}.0\",\n",
        "                    'section_title': section_title,\n",
        "                    'content': f\"Section {section_num}: {section_title}\\n\\n{section_content}\",\n",
        "                    'content_type': 'section',\n",
        "                    'word_count': len(section_content.split()),\n",
        "                    'char_count': len(section_content),\n",
        "                })\n",
        "        return sections\n",
        "\n",
        "    def _add_contextual_info(self, chunks: List[Dict], full_text: str) -> List[Dict]:\n",
        "        enhanced_chunks = []\n",
        "        for chunk in chunks:\n",
        "            enhanced_content = self._build_contextual_content(chunk, chunks)\n",
        "            enhanced_chunk = chunk.copy()\n",
        "            enhanced_chunk['enhanced_content'] = enhanced_content\n",
        "            enhanced_chunks.append(enhanced_chunk)\n",
        "        return enhanced_chunks\n",
        "\n",
        "    def _build_contextual_content(self, chunk: Dict, all_chunks: List[Dict]) -> str:\n",
        "        content_parts = [chunk['content']]\n",
        "        if chunk['content_type'] == 'clause':\n",
        "            related_defs = self._find_related_definitions(chunk, all_chunks)\n",
        "            if related_defs:\n",
        "                content_parts.append(\"Relevant definitions:\")\n",
        "                for def_chunk in related_defs[:2]:\n",
        "                    content_parts.append(f\"- {def_chunk['content']}\")\n",
        "        section_context = self._find_section_context(chunk, all_chunks)\n",
        "        if section_context:\n",
        "            content_parts.insert(0, f\"Context: {section_context}\")\n",
        "        return \"\\n\".join(content_parts)\n",
        "\n",
        "    def _find_related_definitions(self, chunk: Dict, all_chunks: List[Dict]) -> List[Dict]:\n",
        "        definitions = [c for c in all_chunks if c['content_type'] == 'definition']\n",
        "        related = []\n",
        "        chunk_content_lower = chunk['content'].lower()\n",
        "        for def_chunk in definitions:\n",
        "            term_lower = def_chunk['term'].lower()\n",
        "            if term_lower in chunk_content_lower:\n",
        "                related.append(def_chunk)\n",
        "        return related\n",
        "\n",
        "    def _find_section_context(self, chunk: Dict, all_chunks: List[Dict]) -> Optional[str]:\n",
        "        sections = [c for c in all_chunks if c['content_type'] == 'section']\n",
        "        clause_num = chunk['clause_number']\n",
        "        if '.' in clause_num:\n",
        "            section_num = clause_num.split('.')[0]\n",
        "            for section in sections:\n",
        "                if section['clause_number'].startswith(f\"{section_num}.\"):\n",
        "                    return section.get('section_title', '')\n",
        "        return None\n",
        "\n",
        "    def _is_duplicate_clause(self, existing_clauses: List[Dict], clause_num: str) -> bool:\n",
        "        return any(c['clause_number'] == clause_num for c in existing_clauses)\n",
        "\n",
        "# Chunker (re-instantiated after definition)\n",
        "chunker = PolicyDocumentChunker()\n",
        "\n",
        "def build_bm25_index(texts: List[str]) -> BM25Okapi:\n",
        "    \"\"\"Builds a BM25 index from a list of text documents.\"\"\"\n",
        "    tokenized_corpus = [doc.split() for doc in texts]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "    return bm25\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    # Use the chunker from the outer scope\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "# Load and chunk JCI, split into smaller pieces, build FAISS and BM25\n",
        "validate_pdf_path(JCI_PDF)\n",
        "logger.info(\"Loading and chunking JCI standards...\")\n",
        "jci_chunks = load_and_chunk_pdf(JCI_PDF)\n",
        "\n",
        "def split_jci_pieces(chunks, size, overlap):\n",
        "    splitter_local = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=size,\n",
        "        chunk_overlap=overlap,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
        "    )\n",
        "    out_texts, out_metas = [], []\n",
        "    for c in chunks:\n",
        "        content = c.get(\"content\", \"\")\n",
        "        if not content:\n",
        "            continue\n",
        "        pieces = splitter_local.split_text(content)\n",
        "        base_meta = {\"section\": c.get(\"clause_number\", \"n/a\")}\n",
        "        for idx, piece in enumerate(pieces):\n",
        "            piece = piece.strip()\n",
        "            if len(piece) >= 20:\n",
        "                out_texts.append(piece)\n",
        "                out_metas.append({**base_meta, \"piece_index\": idx})\n",
        "    return out_texts, out_metas\n",
        "\n",
        "PRIMARY_SIZE, PRIMARY_OVERLAP = 1500, 200\n",
        "split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, PRIMARY_SIZE, PRIMARY_OVERLAP)\n",
        "\n",
        "def build_faiss_in_batches(texts, metadatas, embedder, batch_size=64):\n",
        "    assert len(texts) == len(metadatas)\n",
        "    if not texts:\n",
        "        raise ValueError(\"No texts to index.\")\n",
        "    first_end = min(batch_size, len(texts))\n",
        "    db = FAISS.from_texts(texts[:first_end], embedder, metadatas=metadatas[:first_end])\n",
        "    for i in range(first_end, len(texts), batch_size):\n",
        "        j = min(i + batch_size, len(texts))\n",
        "        db.add_texts(texts[i:j], metadatas=metadatas[i:j])\n",
        "        time.sleep(0.2)\n",
        "    return db\n",
        "\n",
        "try:\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=64)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (size {PRIMARY_SIZE})\")\n",
        "except Exception as e:\n",
        "    logger.warning(f\"Primary JCI embedding failed ({e}). Retrying with smaller pieces.\")\n",
        "    FALLBACK_SIZE, FALLBACK_OVERLAP = 900, 150\n",
        "    split_jci_texts, split_jci_metadatas = split_jci_pieces(jci_chunks, FALLBACK_SIZE, FALLBACK_OVERLAP)\n",
        "    jci_db = build_faiss_in_batches(split_jci_texts, split_jci_metadatas, embeddings, batch_size=48)\n",
        "    logger.info(f\"FAISS DB built with {len(split_jci_texts)} JCI pieces (fallback size {FALLBACK_SIZE})\")\n",
        "\n",
        "# Build BM25 index\n",
        "jci_bm25 = build_bm25_index(split_jci_texts)\n",
        "logger.info(f\"BM25 index built with {len(split_jci_texts)} JCI pieces\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa66596a"
      },
      "source": [
        "## Modify retrieval function\n",
        "\n",
        "### Subtask:\n",
        "Update the `retrieve_jci_hybrid` function to perform both BM25 and FAISS searches and combine the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9ba0f31"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `retrieve_jci_hybrid` function to incorporate BM25 retrieval, combine it with the existing FAISS retrieval, and return a combined list of unique results. This involves adding parameters for the BM25 index and text corpus, performing BM25 search, merging results with FAISS results, and ensuring uniqueness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3d318a4b"
      },
      "outputs": [],
      "source": [
        "def retrieve_jci_hybrid(clause_number: str, clause_text: str, jci_bm25: BM25Okapi, split_jci_texts: List[str], split_jci_metadatas: List[Dict], k: int = 5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Retrieves relevant JCI standards using a hybrid approach (Guided/BM25 + FAISS).\n",
        "    \"\"\"\n",
        "    expanded_text = expand_query_with_synonyms(clause_text)\n",
        "    mapped = clause_to_sections.get(clause_number)\n",
        "\n",
        "    # Perform BM25 search\n",
        "    tokenized_query = expanded_text.split()\n",
        "    bm25_scores = jci_bm25.get_scores(tokenized_query)\n",
        "    # Get top K indices based on scores\n",
        "    top_n_indices = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:k]\n",
        "    bm25_results = [{\"text\": split_jci_texts[i], \"metadata\": split_jci_metadatas[i]} for i in top_n_indices]\n",
        "\n",
        "    # Perform FAISS search\n",
        "    faiss_docs = jci_db.similarity_search(expanded_text, k=k)\n",
        "    faiss_results = [{\"text\": d.page_content, \"metadata\": d.metadata} for d in faiss_docs]\n",
        "\n",
        "\n",
        "    # Combine results, prioritizing guided sections if mapped\n",
        "    combined_results = []\n",
        "    seen_texts = set()\n",
        "\n",
        "    # Add BM25 results\n",
        "    for result in bm25_results:\n",
        "        if result['text'] not in seen_texts:\n",
        "            combined_results.append(result)\n",
        "            seen_texts.add(result['text'])\n",
        "\n",
        "    # Add FAISS results, prioritizing mapped sections if available\n",
        "    if mapped:\n",
        "        # Add FAISS results from mapped sections first\n",
        "        mapped_faiss_results = [d for d in faiss_results if mapped.lower() in d['metadata'].get('section', '').lower()]\n",
        "        for result in mapped_faiss_results:\n",
        "             if result['text'] not in seen_texts:\n",
        "                combined_results.append(result)\n",
        "                seen_texts.add(result['text'])\n",
        "\n",
        "        # Add remaining FAISS results\n",
        "        remaining_faiss_results = [d for d in faiss_results if mapped.lower() not in d['metadata'].get('section', '').lower()]\n",
        "        for result in remaining_faiss_results:\n",
        "             if result['text'] not in seen_texts:\n",
        "                combined_results.append(result)\n",
        "                seen_texts.add(result['text'])\n",
        "    else:\n",
        "        # If no mapping, add all FAISS results\n",
        "        for result in faiss_results:\n",
        "            if result['text'] not in seen_texts:\n",
        "                combined_results.append(result)\n",
        "                seen_texts.add(result['text'])\n",
        "\n",
        "\n",
        "    # Return top K unique results\n",
        "    return combined_results[:k]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daca0a30"
      },
      "source": [
        "## Combine results\n",
        "\n",
        "### Subtask:\n",
        "Implement a strategy to combine the results from BM25 and FAISS (e.g., re-ranking, reciprocal rank fusion).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96a7c9c8"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `retrieve_jci_hybrid` function to implement Reciprocal Rank Fusion (RRF) for combining BM25 and FAISS results, ensuring the function returns the top K unique results after re-ranking.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "b718ae27"
      },
      "outputs": [],
      "source": [
        "def reciprocal_rank_fusion(results: List[List[Dict]], k: int = 60) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Applies Reciprocal Rank Fusion to a list of ranked lists of results.\n",
        "\n",
        "    Args:\n",
        "        results: A list where each element is a ranked list of dictionaries,\n",
        "                 each dictionary containing 'text' and 'metadata'.\n",
        "        k: The constant used in the RRF formula (1/ (k + rank)).\n",
        "\n",
        "    Returns:\n",
        "        A single list of unique results ranked by their RRF score.\n",
        "    \"\"\"\n",
        "    fused_scores = {}\n",
        "    document_map = {}\n",
        "\n",
        "    for rank_list in results:\n",
        "        for rank, doc in enumerate(rank_list):\n",
        "            text = doc['text']\n",
        "            if text not in fused_scores:\n",
        "                fused_scores[text] = 0.0\n",
        "                document_map[text] = doc # Store the original document object\n",
        "\n",
        "            # RRF formula: 1 / (k + rank)\n",
        "            score = 1.0 / (k + rank + 1)  # +1 because rank is 0-based\n",
        "            fused_scores[text] += score\n",
        "\n",
        "    # Sort documents by fused score in descending order\n",
        "    sorted_docs = sorted(fused_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Return the re-ranked documents\n",
        "    return [document_map[text] for text, score in sorted_docs]\n",
        "\n",
        "\n",
        "def retrieve_jci_hybrid(clause_number: str, clause_text: str, jci_bm25: BM25Okapi, split_jci_texts: List[str], split_jci_metadatas: List[Dict], k: int = 5) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Retrieves relevant JCI standards using a hybrid approach (BM25 + FAISS) and\n",
        "    combines results using Reciprocal Rank Fusion (RRF).\n",
        "    \"\"\"\n",
        "    expanded_text = expand_query_with_synonyms(clause_text)\n",
        "\n",
        "    # Perform BM25 search\n",
        "    tokenized_query = expanded_text.split()\n",
        "    bm25_scores = jci_bm25.get_scores(tokenized_query)\n",
        "    # Get top N indices for RRF (N is typically larger than final K)\n",
        "    N_rrf = 2 * k # Retrieve more documents for RRF\n",
        "    top_n_indices_bm25 = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:N_rrf]\n",
        "    bm25_results = [{\"text\": split_jci_texts[i], \"metadata\": split_jci_metadatas[i]} for i in top_n_indices_bm25]\n",
        "\n",
        "    # Perform FAISS search\n",
        "    faiss_docs = jci_db.similarity_search(expanded_text, k=N_rrf) # Retrieve more documents for RRF\n",
        "    faiss_results = [{\"text\": d.page_content, \"metadata\": d.metadata} for d in faiss_docs]\n",
        "\n",
        "    # Combine and re-rank using RRF\n",
        "    combined_and_reranked = reciprocal_rank_fusion([bm25_results, faiss_results], k=60)\n",
        "\n",
        "    # Apply guided retrieval filter *after* RRF for potential boost (optional, or prior to RRF)\n",
        "    # For simplicity here, we'll just take the top K RRF results.\n",
        "    # A more complex approach could boost RRF scores based on guided mapping.\n",
        "\n",
        "    # Filter by mapped sections if a strong preference is needed (Alternative to RRF score boosting)\n",
        "    # mapped = clause_to_sections.get(clause_number)\n",
        "    # if mapped:\n",
        "    #     filtered_reranked = [doc for doc in combined_and_reranked if mapped.lower() in doc['metadata'].get('section', '').lower()]\n",
        "    #     # Take top K from filtered, then fill with top from original reranked if needed\n",
        "    #     final_results = filtered_reranked[:k]\n",
        "    #     if len(final_results) < k:\n",
        "    #         seen_texts = {doc['text'] for doc in final_results}\n",
        "    #         for doc in combined_and_reranked:\n",
        "    #             if doc['text'] not in seen_texts and len(final_results) < k:\n",
        "    #                 final_results.append(doc)\n",
        "    # else:\n",
        "    #     final_results = combined_and_reranked[:k]\n",
        "\n",
        "    # Returning top K from RRF\n",
        "    return combined_and_reranked[:k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb2f8822"
      },
      "source": [
        "## Test and evaluate\n",
        "\n",
        "### Subtask:\n",
        "Run the analysis with the updated retrieval and potentially add evaluation metrics to assess the impact of hybrid retrieval.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a7fc17b"
      },
      "source": [
        "**Reasoning**:\n",
        "Execute the code cell that runs the batch analysis to use the updated hybrid retrieval function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "194d0ceb",
        "outputId": "2dbb1acb-9002-48ae-ca6b-f57284e29ee2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ComplianceAnalysis' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2948566049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run batches and save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_results\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mComplianceAnalysis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClauseComparisonAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ComplianceAnalysis' is not defined"
          ]
        }
      ],
      "source": [
        "# Run batches and save\n",
        "all_results: List[ComplianceAnalysis] = []\n",
        "\n",
        "# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\n",
        "analyzer = ClauseComparisonAnalyzer(api_key=os.getenv(\"OPENAI_API_KEY\"), model=MODEL)\n",
        "\n",
        "# Use the correct function signature for retrieve_jci_hybrid\n",
        "def batch_analyze_clauses_with_progress(chunks: List[Dict], bm25_index: BM25Okapi, bm25_texts: List[str], bm25_metadatas: List[Dict]) -> List[ComplianceAnalysis]:\n",
        "    results: List[ComplianceAnalysis] = []\n",
        "    work_items = [c for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown']\n",
        "\n",
        "    with tqdm(total=len(work_items), desc=\"Analyzing clauses\") as pbar:\n",
        "        for chunk in work_items:\n",
        "            clause_number = chunk['clause_number']\n",
        "            clause_text = chunk.get('enhanced_content', chunk.get('content', ''))\n",
        "            # Pass the necessary BM25 index components\n",
        "            jci_refs = retrieve_jci_hybrid(clause_number, clause_text, bm25_index, bm25_texts, bm25_metadatas)\n",
        "            try:\n",
        "                analysis = analyzer.compare_clause_to_jci(clause_number, clause_text, jci_refs)\n",
        "                results.append(analysis)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Analysis failed for clause {clause_number}: {e}\")\n",
        "                results.append(\n",
        "                    ComplianceAnalysis(\n",
        "                        clause_number=clause_number,\n",
        "                        compliance_status=ComplianceStatus.INSUFFICIENT_INFO,\n",
        "                        confidence_score=0.0,\n",
        "                        key_gaps=[f\"Analysis failed: {str(e)}\"],\n",
        "                        required_changes=[\"Retry analysis\"],\n",
        "                        jci_references=[],\n",
        "                        risk_level=\"Unknown\",\n",
        "                        full_analysis=f\"Error: {str(e)}\"\n",
        "                    )\n",
        "                )\n",
        "            time.sleep(RATE_LIMIT_DELAY)\n",
        "            pbar.update(1)\n",
        "    return results\n",
        "\n",
        "# Call the batch analysis function with the BM25 index components\n",
        "# Ensure split_jci_texts and split_jci_metadatas are accessible from the scope\n",
        "# If not, you might need to re-run the cell that creates them or pass them explicitly.\n",
        "# Assuming they are accessible from the previous execution:\n",
        "for i in range(0, len(policy_chunks), BATCH_SIZE):\n",
        "    batch = policy_chunks[i:i+BATCH_SIZE]\n",
        "    logger.info(f\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\")\n",
        "    batch_results = batch_analyze_clauses_with_progress(batch, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "    all_results.extend(batch_results)\n",
        "\n",
        "logger.info(f\"Total analyzed: {len(all_results)}\")\n",
        "\n",
        "# Save to Excel\n",
        "def save_comparison_results(analyses: List[ComplianceAnalysis], output_file: str):\n",
        "    data = []\n",
        "    for analysis in analyses:\n",
        "        data.append({\n",
        "            'clause_number': analysis.clause_number,\n",
        "            'compliance_status': analysis.compliance_status.value,\n",
        "            'confidence_score': f\"{analysis.confidence_score:.0%}\",\n",
        "            'risk_level': analysis.risk_level,\n",
        "            'gaps_identified': ' | '.join(analysis.key_gaps),\n",
        "            'required_changes': ' | '.join(analysis.required_changes),\n",
        "            'jci_standards_cited': ' | '.join(analysis.jci_references),\n",
        "            'detailed_analysis': analysis.full_analysis\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        'total_analyzed': len(analyses),\n",
        "        'compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.COMPLIANT]),\n",
        "        'partially_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.PARTIALLY_COMPLIANT]),\n",
        "        'non_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.NON_COMPLIANT]),\n",
        "        'high_risk': len([a for a in analyses if 'high' in a.risk_level.lower()]),\n",
        "    }\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(data).to_excel(writer, sheet_name='Clause Analysis', index=False)\n",
        "        pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "save_comparison_results(all_results, \"policy_vs_jci_hybrid.xlsx\")\n",
        "logger.info(\"Results saved to policy_vs_jci_hybrid.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b6f9e0a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `ComplianceAnalysis` was not defined. This indicates the class definition was not available in the current execution scope. The code cell defining `ComplianceAnalysis` needs to be re-executed or its definition included in the current cell. Since the definition is somewhat long, re-executing the cell that defines it is more efficient. I will also include the definitions of `ComplianceStatus` and `ClauseComparisonAnalyzer` as they are likely in the same original cell and are also needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "l6K0ucVIlK0p"
      },
      "outputs": [],
      "source": [
        "class ComplianceStatus(Enum):\n",
        "    COMPLIANT = \"Compliant\"\n",
        "    PARTIALLY_COMPLIANT = \"Partially Compliant\"\n",
        "    NON_COMPLIANT = \"Non-Compliant\"\n",
        "    INSUFFICIENT_INFO = \"Insufficient Information\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ComplianceAnalysis:\n",
        "    clause_number: str\n",
        "    compliance_status: ComplianceStatus\n",
        "    confidence_score: float\n",
        "    key_gaps: List[str]\n",
        "    required_changes: List[str]\n",
        "    jci_references: List[str]\n",
        "    risk_level: str\n",
        "    full_analysis: str\n",
        "\n",
        "\n",
        "class ClauseComparisonAnalyzer:\n",
        "    def __init__(self, api_key: str, model: str = \"gpt-4o\"):\n",
        "        self.client = OpenAI(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.config = {\n",
        "            'max_tokens': 1000,\n",
        "            'temperature': 0.1,\n",
        "            'top_p': 0.9,\n",
        "        }\n",
        "\n",
        "    def compare_clause_to_jci(self, clause_number: str, clause_text: str, jci_references: List[Dict]) -> ComplianceAnalysis:\n",
        "        prompt = self._build_comparison_prompt(clause_number, clause_text, jci_references)\n",
        "        response = self._call_gpt4o(prompt)\n",
        "        analysis = self._parse_response(response, clause_number)\n",
        "        return analysis\n",
        "\n",
        "    def _build_comparison_prompt(self, clause_number: str, clause_text: str, jci_references: List[Dict]) -> str:\n",
        "        jci_text = self._format_jci_references(jci_references)\n",
        "        return f\"\"\"You are a healthcare compliance expert specializing in JCI hospital accreditation standards.\n",
        "\n",
        "**TASK:** Compare the policy clause against JCI standards and identify specific changes needed.\n",
        "\n",
        "**POLICY CLAUSE {clause_number}:**\n",
        "{clause_text}\n",
        "\n",
        "**RELEVANT JCI STANDARDS:**\n",
        "{jci_text}\n",
        "\n",
        "**ANALYSIS FRAMEWORK:**\n",
        "\n",
        "1. **REQUIREMENT COMPARISON:** Compare each requirement in the policy clause against the JCI standards above.\n",
        "\n",
        "2. **GAP IDENTIFICATION:** Identify specific gaps between policy and JCI requirements.\n",
        "\n",
        "3. **CHANGE SPECIFICATION:** For each gap, specify the exact change needed to achieve compliance.\n",
        "\n",
        "**PROVIDE STRUCTURED OUTPUT:**\n",
        "\n",
        "**COMPLIANCE STATUS:** [Compliant/Partially Compliant/Non-Compliant]\n",
        "\n",
        "**CONFIDENCE LEVEL:** [0-100%]\n",
        "\n",
        "**SPECIFIC GAPS IDENTIFIED:**\n",
        "• [Gap 1]: [Specific difference between policy and JCI standard]\n",
        "• [Gap 2]: [Specific difference between policy and JCI standard]\n",
        "\n",
        "**REQUIRED CHANGES:**\n",
        "• [Change 1]: [Exact modification needed] → [JCI Standard this addresses]\n",
        "• [Change 2]: [Exact modification needed] → [JCI Standard this addresses]\n",
        "\n",
        "**RISK LEVEL:** [High/Medium/Low]\n",
        "\n",
        "**JCI STANDARDS REFERENCED:**\n",
        "• [Standard]: [Specific requirement]\n",
        "\n",
        "Focus on actionable, specific changes rather than general recommendations.\"\"\"\n",
        "\n",
        "    def _format_jci_references(self, references: List[Dict]) -> str:\n",
        "        if not references:\n",
        "            return \"No specific JCI references available for comparison.\"\n",
        "        formatted = []\n",
        "        for i, ref in enumerate(references, 1):\n",
        "            text = ref.get('text', '')\n",
        "            if len(text) > 300:\n",
        "                text = text[:300] + \"...\"\n",
        "            formatted.append(f\"**JCI Reference {i}:**\\n{text}\")\n",
        "        return \"\\n\\n\".join(formatted)\n",
        "\n",
        "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "    def _call_gpt4o(self, prompt: str) -> str:\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are a senior healthcare compliance consultant. Provide specific, actionable analysis focused on exact changes needed for JCI compliance.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            **self.config\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "    def _parse_response(self, response: str, clause_number: str) -> ComplianceAnalysis:\n",
        "        import re as _re\n",
        "        compliance_match = _re.search(r'\\*\\*COMPLIANCE STATUS:\\*\\*\\s*([^\\n]+)', response, _re.IGNORECASE)\n",
        "        compliance_status = ComplianceStatus.INSUFFICIENT_INFO\n",
        "        if compliance_match:\n",
        "            status_text = compliance_match.group(1).strip().lower()\n",
        "            if \"non-compliant\" in status_text:\n",
        "                compliance_status = ComplianceStatus.NON_COMPLIANT\n",
        "            elif \"partially compliant\" in status_text:\n",
        "                compliance_status = ComplianceStatus.PARTIALLY_COMPLIANT\n",
        "            elif \"compliant\" in status_text:\n",
        "                compliance_status = ComplianceStatus.COMPLIANT\n",
        "\n",
        "        confidence_match = _re.search(r'\\*\\*CONFIDENCE LEVEL:\\*\\*\\s*(\\d+)%', response)\n",
        "        confidence_score = float(confidence_match.group(1)) / 100 if confidence_match else 0.0\n",
        "\n",
        "        gaps_section = _re.search(r'\\*\\*SPECIFIC GAPS IDENTIFIED:\\*\\*(.*?)(?=\\*\\*[A-Z ]+:\\*\\*|\\Z)', response, _re.DOTALL)\n",
        "        key_gaps = []\n",
        "        if gaps_section:\n",
        "            gaps_text = gaps_section.group(1)\n",
        "            key_gaps = [g.strip() for g in _re.findall(r'•\\s*([^\\n•]+)', gaps_text) if g.strip()]\n",
        "\n",
        "        changes_section = _re.search(r'\\*\\*REQUIRED CHANGES:\\*\\*(.*?)(?=\\*\\*[A-Z ]+:\\*\\*|\\Z)', response, _re.DOTALL)\n",
        "        required_changes = []\n",
        "        if changes_section:\n",
        "            changes_text = changes_section.group(1)\n",
        "            required_changes = [c.strip() for c in _re.findall(r'•\\s*([^\\n•]+)', changes_text) if c.strip()]\n",
        "\n",
        "        jci_section = _re.search(r'\\*\\*JCI STANDARDS REFERENCED:\\*\\*(.*?)(?=\\*\\*[A-Z ]+:\\*\\*|\\Z)', response, _re.DOTALL)\n",
        "        jci_references = []\n",
        "        if jci_section:\n",
        "            jci_text = jci_section.group(1)\n",
        "            jci_references = [r.strip() for r in _re.findall(r'•\\s*([^\\n•]+)', jci_text) if r.strip()]\n",
        "\n",
        "        risk_match = _re.search(r'\\*\\*RISK LEVEL:\\*\\*\\s*([^\\n]+)', response, _re.IGNORECASE)\n",
        "        risk_level = risk_match.group(1).strip() if risk_match else \"Unknown\"\n",
        "\n",
        "        return ComplianceAnalysis(\n",
        "            clause_number=clause_number,\n",
        "            compliance_status=compliance_status,\n",
        "            confidence_score=confidence_score,\n",
        "            key_gaps=key_gaps,\n",
        "            required_changes=required_changes,\n",
        "            jci_references=jci_references,\n",
        "            risk_level=risk_level,\n",
        "            full_analysis=response\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ef5c86"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ComplianceAnalysis` class and other necessary definitions are now available. I will re-execute the code cell for batch analysis, ensuring the `retrieve_jci_hybrid` function is called with the correct arguments (including the BM25 index components).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5f93cf23",
        "outputId": "8aa62cdb-c71d-499d-c470-35369c10f698"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'MODEL' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2948566049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClauseComparisonAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Use the correct function signature for retrieve_jci_hybrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MODEL' is not defined"
          ]
        }
      ],
      "source": [
        "# Run batches and save\n",
        "all_results: List[ComplianceAnalysis] = []\n",
        "\n",
        "# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\n",
        "analyzer = ClauseComparisonAnalyzer(api_key=os.getenv(\"OPENAI_API_KEY\"), model=MODEL)\n",
        "\n",
        "# Use the correct function signature for retrieve_jci_hybrid\n",
        "def batch_analyze_clauses_with_progress(chunks: List[Dict], bm25_index: BM25Okapi, bm25_texts: List[str], bm25_metadatas: List[Dict]) -> List[ComplianceAnalysis]:\n",
        "    results: List[ComplianceAnalysis] = []\n",
        "    work_items = [c for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown']\n",
        "\n",
        "    with tqdm(total=len(work_items), desc=\"Analyzing clauses\") as pbar:\n",
        "        for chunk in work_items:\n",
        "            clause_number = chunk['clause_number']\n",
        "            clause_text = chunk.get('enhanced_content', chunk.get('content', ''))\n",
        "            # Pass the necessary BM25 index components\n",
        "            jci_refs = retrieve_jci_hybrid(clause_number, clause_text, bm25_index, bm25_texts, bm25_metadatas)\n",
        "            try:\n",
        "                analysis = analyzer.compare_clause_to_jci(clause_number, clause_text, jci_refs)\n",
        "                results.append(analysis)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Analysis failed for clause {clause_number}: {e}\")\n",
        "                results.append(\n",
        "                    ComplianceAnalysis(\n",
        "                        clause_number=clause_number,\n",
        "                        compliance_status=ComplianceStatus.INSUFFICIENT_INFO,\n",
        "                        confidence_score=0.0,\n",
        "                        key_gaps=[f\"Analysis failed: {str(e)}\"],\n",
        "                        required_changes=[\"Retry analysis\"],\n",
        "                        jci_references=[],\n",
        "                        risk_level=\"Unknown\",\n",
        "                        full_analysis=f\"Error: {str(e)}\"\n",
        "                    )\n",
        "                )\n",
        "            time.sleep(RATE_LIMIT_DELAY)\n",
        "            pbar.update(1)\n",
        "    return results\n",
        "\n",
        "# Call the batch analysis function with the BM25 index components\n",
        "# Ensure split_jci_texts and split_jci_metadatas are accessible from the scope\n",
        "# If not, you might need to re-run the cell that creates them or pass them explicitly.\n",
        "# Assuming they are accessible from the previous execution:\n",
        "for i in range(0, len(policy_chunks), BATCH_SIZE):\n",
        "    batch = policy_chunks[i:i+BATCH_SIZE]\n",
        "    logger.info(f\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\")\n",
        "    batch_results = batch_analyze_clauses_with_progress(batch, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "    all_results.extend(batch_results)\n",
        "\n",
        "logger.info(f\"Total analyzed: {len(all_results)}\")\n",
        "\n",
        "# Save to Excel\n",
        "def save_comparison_results(analyses: List[ComplianceAnalysis], output_file: str):\n",
        "    data = []\n",
        "    for analysis in analyses:\n",
        "        data.append({\n",
        "            'clause_number': analysis.clause_number,\n",
        "            'compliance_status': analysis.compliance_status.value,\n",
        "            'confidence_score': f\"{analysis.confidence_score:.0%}\",\n",
        "            'risk_level': analysis.risk_level,\n",
        "            'gaps_identified': ' | '.join(analysis.key_gaps),\n",
        "            'required_changes': ' | '.join(analysis.required_changes),\n",
        "            'jci_standards_cited': ' | '.join(analysis.jci_references),\n",
        "            'detailed_analysis': analysis.full_analysis\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        'total_analyzed': len(analyses),\n",
        "        'compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.COMPLIANT]),\n",
        "        'partially_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.PARTIALLY_COMPLIANT]),\n",
        "        'non_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.NON_COMPLIANT]),\n",
        "        'high_risk': len([a for a in analyses if 'high' in a.risk_level.lower()]),\n",
        "    }\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(data).to_excel(writer, sheet_name='Clause Analysis', index=False)\n",
        "        pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "save_comparison_results(all_results, \"policy_vs_jci_hybrid.xlsx\")\n",
        "logger.info(\"Results saved to policy_vs_jci_hybrid.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a4a4fa2"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `MODEL` was not defined. This variable is used to specify the language model for the `ClauseComparisonAnalyzer`. I need to define this variable before initializing the analyzer. I will also define `RATE_LIMIT_DELAY` and `BATCH_SIZE` as they were likely defined in the same original cell and are used later in the code block. Then I will re-execute the batch analysis code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Y3nPKgdNlROu",
        "outputId": "e1a2116b-736a-45f4-9b4f-8c93a77a2d13"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'policy_chunks' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-395575338.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# If not, you might need to re-run the cell that creates them or pass them explicitly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Assuming they are accessible from the previous execution:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_chunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'policy_chunks' is not defined"
          ]
        }
      ],
      "source": [
        "# Analysis config and batch run\n",
        "MODEL = \"gpt-4o\"\n",
        "RATE_LIMIT_DELAY = 2.0\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Run batches and save\n",
        "all_results: List[ComplianceAnalysis] = []\n",
        "\n",
        "# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\n",
        "analyzer = ClauseComparisonAnalyzer(api_key=os.getenv(\"OPENAI_API_KEY\"), model=MODEL)\n",
        "\n",
        "# Use the correct function signature for retrieve_jci_hybrid\n",
        "def batch_analyze_clauses_with_progress(chunks: List[Dict], bm25_index: BM25Okapi, bm25_texts: List[str], bm25_metadatas: List[Dict]) -> List[ComplianceAnalysis]:\n",
        "    results: List[ComplianceAnalysis] = []\n",
        "    work_items = [c for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown']\n",
        "\n",
        "    with tqdm(total=len(work_items), desc=\"Analyzing clauses\") as pbar:\n",
        "        for chunk in work_items:\n",
        "            clause_number = chunk['clause_number']\n",
        "            clause_text = chunk.get('enhanced_content', chunk.get('content', ''))\n",
        "            # Pass the necessary BM25 index components\n",
        "            jci_refs = retrieve_jci_hybrid(clause_number, clause_text, bm25_index, bm25_texts, bm25_metadatas)\n",
        "            try:\n",
        "                analysis = analyzer.compare_clause_to_jci(clause_number, clause_text, jci_refs)\n",
        "                results.append(analysis)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Analysis failed for clause {clause_number}: {e}\")\n",
        "                results.append(\n",
        "                    ComplianceAnalysis(\n",
        "                        clause_number=clause_number,\n",
        "                        compliance_status=ComplianceStatus.INSUFFICIENT_INFO,\n",
        "                        confidence_score=0.0,\n",
        "                        key_gaps=[f\"Analysis failed: {str(e)}\"],\n",
        "                        required_changes=[\"Retry analysis\"],\n",
        "                        jci_references=[],\n",
        "                        risk_level=\"Unknown\",\n",
        "                        full_analysis=f\"Error: {str(e)}\"\n",
        "                    )\n",
        "                )\n",
        "            time.sleep(RATE_LIMIT_DELAY)\n",
        "            pbar.update(1)\n",
        "    return results\n",
        "\n",
        "# Call the batch analysis function with the BM25 index components\n",
        "# Ensure split_jci_texts and split_jci_metadatas are accessible from the scope\n",
        "# If not, you might need to re-run the cell that creates them or pass them explicitly.\n",
        "# Assuming they are accessible from the previous execution:\n",
        "for i in range(0, len(policy_chunks), BATCH_SIZE):\n",
        "    batch = policy_chunks[i:i+BATCH_SIZE]\n",
        "    logger.info(f\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\")\n",
        "    batch_results = batch_analyze_clauses_with_progress(batch, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "    all_results.extend(batch_results)\n",
        "\n",
        "logger.info(f\"Total analyzed: {len(all_results)}\")\n",
        "\n",
        "# Save to Excel\n",
        "def save_comparison_results(analyses: List[ComplianceAnalysis], output_file: str):\n",
        "    data = []\n",
        "    for analysis in analyses:\n",
        "        data.append({\n",
        "            'clause_number': analysis.clause_number,\n",
        "            'compliance_status': analysis.compliance_status.value,\n",
        "            'confidence_score': f\"{analysis.confidence_score:.0%}\",\n",
        "            'risk_level': analysis.risk_level,\n",
        "            'gaps_identified': ' | '.join(analysis.key_gaps),\n",
        "            'required_changes': ' | '.join(analysis.required_changes),\n",
        "            'jci_standards_cited': ' | '.join(analysis.jci_references),\n",
        "            'detailed_analysis': analysis.full_analysis\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        'total_analyzed': len(analyses),\n",
        "        'compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.COMPLIANT]),\n",
        "        'partially_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.PARTIALLY_COMPLIANT]),\n",
        "        'non_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.NON_COMPLIANT]),\n",
        "        'high_risk': len([a for a in analyses if 'high' in a.risk_level.lower()]),\n",
        "    }\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(data).to_excel(writer, sheet_name='Clause Analysis', index=False)\n",
        "        pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "save_comparison_results(all_results, \"policy_vs_jci_hybrid.xlsx\")\n",
        "logger.info(\"Results saved to policy_vs_jci_hybrid.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dfdde0f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `policy_chunks` was not defined. This variable holds the chunks of the policy document and is needed to iterate through the clauses for analysis. I need to re-execute the code that loads and chunks the policy document to make `policy_chunks` available in the current scope. I will include the definition of `load_and_chunk_pdf` and `validate_pdf_path` as they are needed for loading and chunking, as well as the `POLICY_PDF` variable and the `logger`. I will also include the `chunker` object initialization as it's used by `load_and_chunk_pdf`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "6H9gTsEKlU5M",
        "outputId": "c035f7a9-2ccb-41ba-f591-a38bf0647d19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyzing clauses:   0%|          | 0/10 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'expand_query_with_synonyms' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2679567448.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mbatch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_analyze_clauses_with_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjci_bm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_jci_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_jci_metadatas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2679567448.py\u001b[0m in \u001b[0;36mbatch_analyze_clauses_with_progress\u001b[0;34m(chunks, bm25_index, bm25_texts, bm25_metadatas)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# Pass the necessary BM25 index components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# Assuming jci_bm25, split_jci_texts, split_jci_metadatas are accessible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mjci_refs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_jci_hybrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclause_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclause_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjci_bm25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_jci_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_jci_metadatas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_clause_to_jci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclause_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclause_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjci_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1376946889.py\u001b[0m in \u001b[0;36mretrieve_jci_hybrid\u001b[0;34m(clause_number, clause_text, jci_bm25, split_jci_texts, split_jci_metadatas, k)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mcombines\u001b[0m \u001b[0mresults\u001b[0m \u001b[0musing\u001b[0m \u001b[0mReciprocal\u001b[0m \u001b[0mRank\u001b[0m \u001b[0mFusion\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRRF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mexpanded_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_query_with_synonyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclause_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Perform BM25 search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'expand_query_with_synonyms' is not defined"
          ]
        }
      ],
      "source": [
        "# Load policy PDF, chunk, and save chunking results\n",
        "# Define necessary variables and functions if not in scope\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\" # <- change as needed\n",
        "\n",
        "# Re-define logger and chunker if necessary\n",
        "# Assuming setup_logging and PolicyDocumentChunker are defined in previous cells\n",
        "# logger = setup_logging() # Assuming this was run previously\n",
        "# chunker = PolicyDocumentChunker() # Assuming this was run previously\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    # Use the chunker from the outer scope\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "\n",
        "validate_pdf_path(POLICY_PDF)\n",
        "logger.info(\"Loading and chunking policy document...\")\n",
        "policy_chunks = load_and_chunk_pdf(POLICY_PDF)\n",
        "# policy_analysis = analyze_chunking_results(policy_chunks) # No need to re-calculate analysis here\n",
        "logger.info(f\"Chunking complete: {len(policy_chunks)} chunks found.\")\n",
        "\n",
        "# No need to save chunking results again unless they changed, which they didn't\n",
        "# pd.DataFrame(policy_chunks).to_excel(\"enhanced_chunking_results.xlsx\", index=False)\n",
        "# logger.info(\"Saved enhanced_chunking_results.xlsx\")\n",
        "\n",
        "\n",
        "# Analysis config and batch run (re-included from previous attempt)\n",
        "MODEL = \"gpt-4o\"\n",
        "RATE_LIMIT_DELAY = 2.0\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Run batches and save\n",
        "all_results: List[ComplianceAnalysis] = []\n",
        "\n",
        "# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\n",
        "analyzer = ClauseComparisonAnalyzer(api_key=os.getenv(\"OPENAI_API_KEY\"), model=MODEL)\n",
        "\n",
        "# Use the correct function signature for retrieve_jci_hybrid\n",
        "def batch_analyze_clauses_with_progress(chunks: List[Dict], bm25_index: BM25Okapi, bm25_texts: List[str], bm25_metadatas: List[Dict]) -> List[ComplianceAnalysis]:\n",
        "    results: List[ComplianceAnalysis] = []\n",
        "    work_items = [c for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown']\n",
        "\n",
        "    with tqdm(total=len(work_items), desc=\"Analyzing clauses\") as pbar:\n",
        "        for chunk in work_items:\n",
        "            clause_number = chunk['clause_number']\n",
        "            clause_text = chunk.get('enhanced_content', chunk.get('content', ''))\n",
        "            # Pass the necessary BM25 index components\n",
        "            # Assuming jci_bm25, split_jci_texts, split_jci_metadatas are accessible\n",
        "            jci_refs = retrieve_jci_hybrid(clause_number, clause_text, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "            try:\n",
        "                analysis = analyzer.compare_clause_to_jci(clause_number, clause_text, jci_refs)\n",
        "                results.append(analysis)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Analysis failed for clause {clause_number}: {e}\")\n",
        "                results.append(\n",
        "                    ComplianceAnalysis(\n",
        "                        clause_number=clause_number,\n",
        "                        compliance_status=ComplianceStatus.INSUFFICIENT_INFO,\n",
        "                        confidence_score=0.0,\n",
        "                        key_gaps=[f\"Analysis failed: {str(e)}\"],\n",
        "                        required_changes=[\"Retry analysis\"],\n",
        "                        jci_references=[],\n",
        "                        risk_level=\"Unknown\",\n",
        "                        full_analysis=f\"Error: {str(e)}\"\n",
        "                    )\n",
        "                )\n",
        "            time.sleep(RATE_LIMIT_DELAY)\n",
        "            pbar.update(1)\n",
        "    return results\n",
        "\n",
        "# Call the batch analysis function with the BM25 index components\n",
        "# Ensure jci_bm25, split_jci_texts, and split_jci_metadatas are accessible from the scope.\n",
        "# Assuming they are accessible from the previous execution where the BM25 index was built.\n",
        "for i in range(0, len(policy_chunks), BATCH_SIZE):\n",
        "    batch = policy_chunks[i:i+BATCH_SIZE]\n",
        "    logger.info(f\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\")\n",
        "    batch_results = batch_analyze_clauses_with_progress(batch, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "    all_results.extend(batch_results)\n",
        "\n",
        "logger.info(f\"Total analyzed: {len(all_results)}\")\n",
        "\n",
        "# Save to Excel\n",
        "def save_comparison_results(analyses: List[ComplianceAnalysis], output_file: str):\n",
        "    data = []\n",
        "    for analysis in analyses:\n",
        "        data.append({\n",
        "            'clause_number': analysis.clause_number,\n",
        "            'compliance_status': analysis.compliance_status.value,\n",
        "            'confidence_score': f\"{analysis.confidence_score:.0%}\",\n",
        "            'risk_level': analysis.risk_level,\n",
        "            'gaps_identified': ' | '.join(analysis.key_gaps),\n",
        "            'required_changes': ' | '.join(analysis.required_changes),\n",
        "            'jci_standards_cited': ' | '.join(analysis.jci_references),\n",
        "            'detailed_analysis': analysis.full_analysis\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        'total_analyzed': len(analyses),\n",
        "        'compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.COMPLIANT]),\n",
        "        'partially_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.PARTIALLY_COMPLIANT]),\n",
        "        'non_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.NON_COMPLIANT]),\n",
        "        'high_risk': len([a for a in analyses if 'high' in a.risk_level.lower()]),\n",
        "    }\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(data).to_excel(writer, sheet_name='Clause Analysis', index=False)\n",
        "        pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "save_comparison_results(all_results, \"policy_vs_jci_hybrid.xlsx\")\n",
        "logger.info(\"Results saved to policy_vs_jci_hybrid.xlsx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e85e8217"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because `expand_query_with_synonyms` was not defined. This function is used within `retrieve_jci_hybrid` to expand the query using synonyms. I need to re-execute the code cell that defines this function and the `synonyms` dictionary, as well as the `clause_to_sections` dictionary which is also used in `retrieve_jci_hybrid`. Then I will re-execute the batch analysis code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipTY-bAulZFx",
        "outputId": "402ca274-42eb-433e-da33-2174427fbcd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Analyzing clauses: 100%|██████████| 10/10 [01:11<00:00,  7.14s/it]\n",
            "Analyzing clauses: 100%|██████████| 10/10 [01:16<00:00,  7.61s/it]\n",
            "Analyzing clauses: 100%|██████████| 6/6 [00:56<00:00,  9.40s/it]\n"
          ]
        }
      ],
      "source": [
        "# Guided retrieval configuration (re-included)\n",
        "clause_to_sections = {\n",
        "    \"4.1\": \"ACC.01.00 ME1\",\n",
        "    \"4.3\": \"ACC.04.05 ME1\",\n",
        "    \"4.4\": \"ACC.01.00 ME3\",\n",
        "    \"4.5\": \"ACC.01.00 ME2\",\n",
        "    \"4.6\": \"ACC.03.00 ME1\",\n",
        "    \"4.7\": \"ACC.03.00 ME3\",\n",
        "    \"4.8\": \"ACC.03.01 ME3\",\n",
        "    \"5.1.1\": \"ACC.03.01 ME2 and ME3\",\n",
        "    \"5.1.2\": \"ACC.03.00 ME1\",\n",
        "    \"5.1.3\": \"ACC.01.00 ME5, ACC.03.00 ME2, ME3 and ME4\",\n",
        "    \"5.1.4\": \"ACC.03.00 ME6, ACC.02.02 ME2\",\n",
        "    \"5.1.5\": \"ACC.03.00 ME6\",\n",
        "    \"5.1.8\": \"ACC.03.00 ME5, ACC.03.01 ME1, ME2 and ME3\",\n",
        "    \"5.3.1\": \"ACC.01.00 ME6\",\n",
        "    \"5.3.2\": \"ACC.03.01 ME1, ME2 and ME3\",\n",
        "    \"5.3.3\": \"ACC.03.01 ME3\",\n",
        "    \"5.3.4\": \"ACC.03.01 ME3\",\n",
        "    \"5.4.1\": \"ACC.03.01 ME3\",\n",
        "    \"5.5.1\": \"ACC.03.01 ME1 and ME3\",\n",
        "    \"5.5.2\": \"ACC.03.00 ME6\",\n",
        "    \"5.6\": \"ACC.03.01 ME3\",\n",
        "    \"5.6.1\": \"Ministry of Health Circular No. MH 53:08/4 vol 6 – Guidelines for Inter-Hospital Transfer\",\n",
        "    \"5.6.2\": \"ACC.03.00 ME6\",\n",
        "    \"5.6.3\": \"ACC.03.00 ME5\",\n",
        "    \"5.6.4\": \"ACC.03.01 ME1, ME2 and ME3\",\n",
        "    \"5.7\": \"ACC.03.01 ME and ME3\",\n",
        "}\n",
        "\n",
        "synonyms = {\n",
        "    \"transfer\": [\"handover\", \"relocation\", \"patient movement\"],\n",
        "    \"policy\": [\"guideline\", \"procedure\"],\n",
        "    \"emergency\": [\"urgent\", \"critical\", \"immediate\"],\n",
        "}\n",
        "\n",
        "def expand_query_with_synonyms(query: str) -> str:\n",
        "    words = query.split()\n",
        "    expanded = []\n",
        "    for w in words:\n",
        "        expanded.append(w)\n",
        "        if w.lower() in synonyms:\n",
        "            expanded.extend(synonyms[w.lower()])\n",
        "    return \" \".join(expanded)\n",
        "\n",
        "# Define reciprocal_rank_fusion and retrieve_jci_hybrid if not in scope\n",
        "# Assuming reciprocal_rank_fusion and retrieve_jci_hybrid are defined in a previous cell\n",
        "# def reciprocal_rank_fusion(...)\n",
        "# def retrieve_jci_hybrid(...)\n",
        "\n",
        "\n",
        "# Load policy PDF, chunk, and save chunking results (re-included)\n",
        "# Define necessary variables and functions if not in scope\n",
        "POLICY_PDF = \"/content/old Transfer 290523 .pdf\" # <- change as needed\n",
        "\n",
        "# Re-define logger and chunker if necessary\n",
        "# Assuming setup_logging and PolicyDocumentChunker are defined in previous cells\n",
        "# logger = setup_logging() # Assuming this was run previously\n",
        "# chunker = PolicyDocumentChunker() # Assuming this was run previously\n",
        "\n",
        "def validate_pdf_path(pdf_path: str) -> None:\n",
        "    path = Path(pdf_path)\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "    if path.suffix.lower() != '.pdf':\n",
        "        raise ValueError(f\"File must be a PDF: {pdf_path}\")\n",
        "\n",
        "def load_and_chunk_pdf(pdf_path: str) -> List[Dict]:\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load()\n",
        "    full_text = \"\\n\".join([page.page_content for page in pages])\n",
        "    # Use the chunker from the outer scope\n",
        "    chunks = chunker.extract_comprehensive_chunks(full_text)\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk.update({\n",
        "            'chunk_id': f\"{os.path.basename(pdf_path)}::chunk_{i+1}\",\n",
        "            'source_file': pdf_path,\n",
        "        })\n",
        "    return chunks\n",
        "\n",
        "\n",
        "validate_pdf_path(POLICY_PDF)\n",
        "logger.info(\"Loading and chunking policy document...\")\n",
        "policy_chunks = load_and_chunk_pdf(POLICY_PDF)\n",
        "# policy_analysis = analyze_chunking_results(policy_chunks) # No need to re-calculate analysis here\n",
        "logger.info(f\"Chunking complete: {len(policy_chunks)} chunks found.\")\n",
        "\n",
        "# No need to save chunking results again unless they changed, which they didn't\n",
        "# pd.DataFrame(policy_chunks).to_excel(\"enhanced_chunking_results.xlsx\", index=False)\n",
        "# logger.info(\"Saved enhanced_chunking_results.xlsx\")\n",
        "\n",
        "\n",
        "# Analysis config and batch run (re-included from previous attempt)\n",
        "MODEL = \"gpt-4o\"\n",
        "RATE_LIMIT_DELAY = 2.0\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "# Run batches and save\n",
        "all_results: List[ComplianceAnalysis] = []\n",
        "\n",
        "# Re-initialize the analyzer to use the latest model and potentially pick up new environment variables\n",
        "# Assuming ComplianceAnalysis and ClauseComparisonAnalyzer are defined in a previous cell\n",
        "# analyzer = ClauseComparisonAnalyzer(api_key=os.getenv(\"OPENAI_API_KEY\"), model=MODEL) # Assuming this was run previously\n",
        "\n",
        "# Use the correct function signature for retrieve_jci_hybrid\n",
        "def batch_analyze_clauses_with_progress(chunks: List[Dict], bm25_index: BM25Okapi, bm25_texts: List[str], bm25_metadatas: List[Dict]) -> List[ComplianceAnalysis]:\n",
        "    results: List[ComplianceAnalysis] = []\n",
        "    work_items = [c for c in chunks if c.get('clause_number') and c['clause_number'] != 'unknown']\n",
        "\n",
        "    with tqdm(total=len(work_items), desc=\"Analyzing clauses\") as pbar:\n",
        "        for chunk in work_items:\n",
        "            clause_number = chunk['clause_number']\n",
        "            clause_text = chunk.get('enhanced_content', chunk.get('content', ''))\n",
        "            # Pass the necessary BM25 index components\n",
        "            # Assuming jci_bm25, split_jci_texts, split_jci_metadatas are accessible\n",
        "            jci_refs = retrieve_jci_hybrid(clause_number, clause_text, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "            try:\n",
        "                analysis = analyzer.compare_clause_to_jci(clause_number, clause_text, jci_refs)\n",
        "                results.append(analysis)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Analysis failed for clause {clause_number}: {e}\")\n",
        "                results.append(\n",
        "                    ComplianceAnalysis(\n",
        "                        clause_number=clause_number,\n",
        "                        compliance_status=ComplianceStatus.INSUFFICIENT_INFO,\n",
        "                        confidence_score=0.0,\n",
        "                        key_gaps=[f\"Analysis failed: {str(e)}\"],\n",
        "                        required_changes=[\"Retry analysis\"],\n",
        "                        jci_references=[],\n",
        "                        risk_level=\"Unknown\",\n",
        "                        full_analysis=f\"Error: {str(e)}\"\n",
        "                    )\n",
        "                )\n",
        "            time.sleep(RATE_LIMIT_DELAY)\n",
        "            pbar.update(1)\n",
        "    return results\n",
        "\n",
        "# Call the batch analysis function with the BM25 index components\n",
        "# Ensure jci_bm25, split_jci_texts, and split_jci_metadatas are accessible from the scope.\n",
        "# Assuming they are accessible from the previous execution where the BM25 index was built.\n",
        "for i in range(0, len(policy_chunks), BATCH_SIZE):\n",
        "    batch = policy_chunks[i:i+BATCH_SIZE]\n",
        "    logger.info(f\"Processing batch {i//BATCH_SIZE + 1} with {len(batch)} clauses...\")\n",
        "    batch_results = batch_analyze_clauses_with_progress(batch, jci_bm25, split_jci_texts, split_jci_metadatas)\n",
        "    all_results.extend(batch_results)\n",
        "\n",
        "logger.info(f\"Total analyzed: {len(all_results)}\")\n",
        "\n",
        "# Save to Excel\n",
        "def save_comparison_results(analyses: List[ComplianceAnalysis], output_file: str):\n",
        "    data = []\n",
        "    for analysis in analyses:\n",
        "        data.append({\n",
        "            'clause_number': analysis.clause_number,\n",
        "            'compliance_status': analysis.compliance_status.value,\n",
        "            'confidence_score': f\"{analysis.confidence_score:.0%}\",\n",
        "            'risk_level': analysis.risk_level,\n",
        "            'gaps_identified': ' | '.join(analysis.key_gaps),\n",
        "            'required_changes': ' | '.join(analysis.required_changes),\n",
        "            'jci_standards_cited': ' | '.join(analysis.jci_references),\n",
        "            'detailed_analysis': analysis.full_analysis\n",
        "        })\n",
        "\n",
        "    summary = {\n",
        "        'total_analyzed': len(analyses),\n",
        "        'compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.COMPLIANT]),\n",
        "        'partially_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.PARTIALLY_COMPLIANT]),\n",
        "        'non_compliant': len([a for a in analyses if a.compliance_status == ComplianceStatus.NON_COMPLIANT]),\n",
        "        'high_risk': len([a for a in analyses if 'high' in a.risk_level.lower()]),\n",
        "    }\n",
        "\n",
        "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
        "        pd.DataFrame(data).to_excel(writer, sheet_name='Clause Analysis', index=False)\n",
        "        pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "save_comparison_results(all_results, \"policy_vs_jci_hybrid.xlsx\")\n",
        "logger.info(\"Results saved to policy_vs_jci_hybrid.xlsx\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
